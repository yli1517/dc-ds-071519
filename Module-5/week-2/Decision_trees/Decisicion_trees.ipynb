{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "<img src= \"img_murat/bob_ross.jpg\" style=\"height:400px\">\n",
    "\n",
    "\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Describe decision tree methods for classification and regression.\n",
    "\n",
    "- Apply a decision tree regressor with sklearn.\n",
    "\n",
    "- Define Gini impurity index, Shannon's entropy.\n",
    "\n",
    "- Compare decision trees with the models we learnt before. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Regression Trees \n",
    "[dataset](https://www.kaggle.com/floser/hitters/downloads/hitters.zip/1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitters = pd.read_csv('data/Hitters.csv')\n",
    "\n",
    "hitters.dropna(inplace  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years = hitters.loc[:, ['Years', 'Hits']] \n",
    "df_years['salary'] = hitters.Salary.apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years</th>\n",
       "      <th>Hits</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>81</td>\n",
       "      <td>6.163315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>6.173786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>141</td>\n",
       "      <td>6.214608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4.516339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>169</td>\n",
       "      <td>6.620073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years  Hits    salary\n",
       "1     14    81  6.163315\n",
       "2      3   130  6.173786\n",
       "3     11   141  6.214608\n",
       "4      2    87  4.516339\n",
       "5     11   169  6.620073"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_years.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"img_murat/hitters_salary2.png\" style=\"height:500px\">\n",
    "<img src= \"img_murat/partition_of_set.png\" style=\"height:500px\">\n",
    "\n",
    "### Terminology\n",
    "<img src= \"img_murat/nodes_branches.png\" style=\"height:200px\">\n",
    "\n",
    "\n",
    "### Another decision tree example and terminology\n",
    "\n",
    "<img src= \"img_murat/terminology1.png\" style=\"height:400px\">\n",
    "\n",
    "\n",
    "### Algorithm \n",
    "\n",
    "- Divide the predictor space $X_1, X_2, \\cdots X_k$ into distinct rectangles $R_1, \\cdots, R_{k}$\n",
    "\n",
    "- For every observation that falls into the region $R_j$ , we make the same prediction, which is simply the mean of the response values for the training observations in $R_j$.\n",
    "\n",
    "#### Obvious questions\n",
    "\n",
    "- Why we divide rectangular regions?\n",
    "\n",
    "- How to construct rectangles $R_1, \\cdots, R_{j}$'s\n",
    "\n",
    "__Goal__\n",
    "\n",
    "Again we try to construct rectangles $R_j$ so that the Residual Sum of Squares is minimum:\n",
    "\n",
    "<img src= \"img_murat/dt_least_square.png\" style=\"height:100px\">\n",
    "\n",
    "- __Problem__ with this approach is too complicated to find!! \n",
    "\n",
    "_ __Solution?__ Greedy algorithm!!\n",
    "\n",
    "Instead of finding best partition, start from one variable and do the best partition.\n",
    "\n",
    "\n",
    "__Summary__\n",
    " \n",
    "- Start with a variable and division that gives the greatest possible reduction in RSS\n",
    "\n",
    "- Continue this approach but only check the RSS in resulting regions.\n",
    "\n",
    "- Stop with a predetermined stopping criteria.\n",
    "\n",
    "<img src= \"img_murat/Partition_with_5_boxes_ISLR.png\" style=\"height:300px\">\n",
    "\n",
    "<img src= \"img_murat/graph_of_partition_with_5_boxes.png\" style=\"height:300px\">\n",
    "\n",
    "\n",
    "\n",
    "### Possible Problems:\n",
    "\n",
    "- Good for training but not for test --> Can you see why?\n",
    "\n",
    "- Overfitting is a common thing with decision trees: Solution is __Tree Pruning!__\n",
    "\n",
    "\n",
    "<img src= \"img_murat/pruning.jpg\" style=\"height:300px\">\n",
    "\n",
    "\n",
    "[Let's check sklearn for pruning methods!!](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "For more on Tree pruning read pg: 307 from ISLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimatorn R2 score:  0.9964804755929203 \n",
      "estimator_importances:  [0.59946586 0.40053414]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "estimator = tree.DecisionTreeRegressor()\n",
    "\n",
    "X = df_years[['Years', 'Hits']]\n",
    "y = df_years[['salary']]\n",
    "\n",
    "estimator.fit(X, y)\n",
    "print('estimatorn R2 score: ', estimator.score(X,y),'\\nestimator_importances: ', estimator.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Trees\n",
    "\n",
    "\n",
    "Q: Can we use the same algorithm?\n",
    "\n",
    "Q1: What might go wrong?  Hint: RSS for classification?\n",
    "\n",
    "Q2: What else can we use for classification?\n",
    "\n",
    "#### Classification Error Rate\n",
    "\n",
    "<img src= \"img_murat/classification_error_rate.png\" style=\"height:100px\">\n",
    "\n",
    "#### Gini Index\n",
    "\n",
    "<img src= \"img_murat/gini.png\" style=\"height:100px\">\n",
    "\n",
    "#### Shannon's Entropy\n",
    "\n",
    "<img src= \"img_murat/entropy.png\" style=\"height:100px\">\n",
    "\n",
    "#### Comparison of different impurity costs:\n",
    "\n",
    "<img src= \"img_murat/gini_classification_entropy.png\" style=\"height:400px\">\n",
    "\n",
    "\n",
    "## Advantages of Tree Methods\n",
    "\n",
    "[Sklearn Documentation](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "<img src= \"img_murat/advantages_of_trees.png\" style=\"height:400px\">\n",
    "\n",
    "## Disadvantages of Tree Methods\n",
    "\n",
    "<img src= \"img_murat/disadvantages_of_trees.png\" style=\"height:200px\">\n",
    "\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "Q: what is information gain criteria? \n",
    "\n",
    "[Watch this video](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
    "\n",
    "Q: What is ID3, C4.5 and CART?\n",
    "\n",
    "[sklearn documentation 1.10.6](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "Q: What are the tricky things that we should watch out in application?\n",
    "\n",
    "[sklearn documentation 1.10.5 - Tips on Practical Use](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "Q: Can sklearn plot the structure of a decision tree?\n",
    "\n",
    "[Check this blog? I didn't fully read this though](https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176)\n",
    "\n",
    "More readings:\n",
    "\n",
    "[ISLR - Chapter 8](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n",
    "\n",
    "[A 61 page chapter from a book. - Looks friendly :)](https://www-users.cs.umn.edu/~kumar001/dmbook/ch4.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining\n",
    "\n",
    "![miners](img/text-miners.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is text mining different? What is text?\n",
    "\n",
    "- Order the words from **SMALLEST** to **LARGEST** units\n",
    " - character\n",
    " - corpora\n",
    " - sentence\n",
    " - word\n",
    " - corpus\n",
    " - paragraph\n",
    " - document\n",
    "\n",
    "(after it is all organized)\n",
    "\n",
    "- Any disagreements about the terms used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "## start small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_test = \"Here is a sentence. Or two, I don't think there will be more.\"\n",
    "token_test_2 = \"i thought this sentence was good.\"\n",
    "token_test_3 = \"Here's a sentence... maybe two. Depending on how you like to count!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here is a sentence',\n",
       " \" Or two, I don't think there will be more\",\n",
       " '',\n",
       " \"Here is a sentence. Or two, I don't think there will be more.\",\n",
       " \"Here is a sentence. Or two, I don't think there will be more.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's tokenize a document... into sentences\n",
    "def make_sentences(doc):\n",
    "    punct = ['.', '!', '?']\n",
    "    sentences = [doc]\n",
    "    for p in punct:\n",
    "        for s in sentences:\n",
    "            sentences.extend(doc.split(p))\n",
    "    return sentences\n",
    "\n",
    "make_sentences(token_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's tokenize a document into words\n",
    "# with these 3 test cases what would you look out for?\n",
    "def tokenize_it(doc):\n",
    "    pass\n",
    "\n",
    "tokenize_it(token_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New library!\n",
    "\n",
    "while we have seen language processing tools in spark, NLTK is its own python library. And of course, it has its own [documentation](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist, word_tokenize\n",
    "import string\n",
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/enkeboll/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamorph = urllib.request.urlopen('http://www.gutenberg.org/cache/epub/5200/pg5200.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "resp = requests.get('http://www.gutenberg.org/cache/epub/5200/pg5200.txt')\n",
    "metamorph = resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(metamorph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xef\\xbb\\xbfThe Project Gutenberg EBook of Metamorphosis, by Franz Kafka\\r\\nTranslated by David Wyllie.\\r\\n\\r\\nThis'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metamorph[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamorph_st = metamorph.decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(metamorph_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your article here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Metamorphosis', 'by', 'Franz', 'Kafka', 'Translated', 'by', 'David', 'Wyllie', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'This', 'is', 'a', 'COPYRIGHTED', 'Project', 'Gutenberg', 'eBook', 'Details', 'Below', 'Please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file', 'Title', 'Metamorphosis', 'Author', 'Franz', 'Kafka', 'Translator', 'David', 'Wyllie', 'Release', 'Date', 'August', 'EBook', 'First', 'posted', 'May', 'Last', 'updated', 'May', 'Language', 'English', 'START', 'OF', 'THIS']\n"
     ]
    }
   ],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "metamorph_tokens_raw = nltk.regexp_tokenize(metamorph_st, pattern)\n",
    "\n",
    "print(metamorph_tokens_raw[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'metamorphosis', 'by', 'franz', 'kafka', 'translated', 'by', 'david', 'wyllie', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'this', 'is', 'a', 'copyrighted', 'project', 'gutenberg', 'ebook', 'details', 'below', 'please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file', 'title', 'metamorphosis', 'author', 'franz', 'kafka', 'translator', 'david', 'wyllie', 'release', 'date', 'august', 'ebook', 'first', 'posted', 'may', 'last', 'updated', 'may', 'language', 'english', 'start', 'of', 'this']\n"
     ]
    }
   ],
   "source": [
    "metamorph_tokens = [i.lower() for i in metamorph_tokens_raw]\n",
    "print(metamorph_tokens[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'metamorphosis', 'franz', 'kafka', 'translated', 'david', 'wyllie', 'use', 'anyone', 'anywhere', 'cost', 'almost', 'restrictions', 'whatsoever', 'may', 'copy', 'give', 'away', 'use', 'terms', 'project', 'license', 'included', 'online', 'www', 'net', 'copyrighted', 'project', 'details', 'please', 'follow', 'copyright', 'guidelines', 'file', 'title', 'metamorphosis', 'author', 'franz', 'kafka', 'translator', 'david', 'wyllie', 'release', 'date', 'august', 'first', 'posted', 'may', 'last', 'updated', 'may', 'language', 'english', 'start', 'project', 'metamorphosis', 'copyright', 'c', 'david', 'wyllie', 'metamorphosis', 'franz', 'kafka', 'translated', 'david', 'wyllie', 'one', 'morning', 'gregor', 'samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'back', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'seemed']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english') + ['would', 'would', 'gutenberg', 'ebook'])\n",
    "stop_words.remove('yourself')\n",
    "metamorph_tokens_stopped = [w for w in metamorph_tokens if not w in stop_words]\n",
    "print(metamorph_tokens_stopped[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming / Lemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming - Porter Stemmer \n",
    "![porter](https://cdn.homebrewersassociation.org/wp-content/uploads/Baltic_Porter_Feature-600x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "example = ['caresses', 'flies', 'flying', 'mules', 'denied',\n",
    "           'deny', 'agreed', 'owned', 'humbled', 'sized',\n",
    "           'meeting', 'stating', 'siezing', 'itemization',\n",
    "           'sensational', 'traditional', 'reference', 'colonizer',\n",
    "           'plotted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress fli fli mule deni deni agre own humbl size meet state siez item sensat tradit refer colon plot\n"
     ]
    }
   ],
   "source": [
    "singles = [stemmer.stem(e) for e in example]\n",
    "print(*singles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming - Snowball Stemmer\n",
    "![snowball](https://localtvwiti.files.wordpress.com/2018/08/gettyimages-936380496.jpg?quality=85&strip=all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic\n",
      "danish\n",
      "dutch\n",
      "english\n",
      "finnish\n",
      "french\n",
      "german\n",
      "hungarian\n",
      "italian\n",
      "norwegian\n",
      "porter\n",
      "portuguese\n",
      "romanian\n",
      "russian\n",
      "spanish\n",
      "swedish\n"
     ]
    }
   ],
   "source": [
    "print(*SnowballStemmer.languages, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "print(stemmer.stem(\"running\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress fli fli mule deni deni agre own humbl size meet state siez item sensat tradit refer colon plot\n"
     ]
    }
   ],
   "source": [
    "singles = [stemmer.stem(e) for e in example]\n",
    "print(*singles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter vs Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous\n",
      "gener\n"
     ]
    }
   ],
   "source": [
    "print(SnowballStemmer(\"english\").stem(\"generously\"))\n",
    "print(SnowballStemmer(\"porter\").stem(\"generously\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Snowball on metamorphesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'metamorphosi', 'franz', 'kafka', 'translat', 'david', 'wylli', 'use', 'anyon', 'anywher', 'cost', 'almost', 'restrict', 'whatsoev', 'may', 'copi', 'give', 'away', 'use', 'term', 'project', 'licens', 'includ', 'onlin', 'www', 'net', 'copyright', 'project', 'detail', 'pleas', 'follow', 'copyright', 'guidelin', 'file', 'titl', 'metamorphosi', 'author', 'franz', 'kafka', 'translat', 'david', 'wylli', 'releas', 'date', 'august', 'first', 'post', 'may', 'last', 'updat', 'may', 'languag', 'english', 'start', 'project', 'metamorphosi', 'copyright', 'c', 'david', 'wylli', 'metamorphosi', 'franz', 'kafka', 'translat', 'david', 'wylli', 'one', 'morn', 'gregor', 'samsa', 'woke', 'troubl', 'dream', 'found', 'transform', 'bed', 'horribl', 'vermin', 'lay', 'armour', 'like', 'back', 'lift', 'head', 'littl', 'could', 'see', 'brown', 'belli', 'slight', 'dome', 'divid', 'arch', 'stiff', 'section', 'bed', 'hard', 'abl', 'cover', 'seem']\n"
     ]
    }
   ],
   "source": [
    "meta_stemmed = [stemmer.stem(word) for word in metamorph_tokens_stopped]\n",
    "print(meta_stemmed[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'denies'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "wnl.lemmatize('denies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is a short list of additional considerations when cleaning text:\n",
    "\n",
    "- Handling large documents and large collections of text documents that do not fit into memory.\n",
    "- Extracting text from markup like HTML, PDF, or other structured document formats.\n",
    "- Transliteration of characters from other languages into English.\n",
    "- Decoding Unicode characters into a normalized form, such as UTF8.\n",
    "- Handling of domain specific words, phrases, and acronyms.\n",
    "- Handling or removing numbers, such as dates and amounts.\n",
    "- Locating and correcting common typos and misspellings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_freqdist = FreqDist(meta_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gregor', 298),\n",
       " ('room', 133),\n",
       " ('could', 120),\n",
       " ('work', 114),\n",
       " ('even', 104),\n",
       " ('father', 102),\n",
       " ('sister', 101),\n",
       " ('door', 97),\n",
       " ('mother', 90),\n",
       " ('project', 88),\n",
       " ('back', 83),\n",
       " ('one', 76),\n",
       " ('time', 74),\n",
       " ('way', 66),\n",
       " ('look', 61),\n",
       " ('tm', 57),\n",
       " ('open', 56),\n",
       " ('use', 55),\n",
       " ('get', 52),\n",
       " ('said', 51),\n",
       " ('littl', 49),\n",
       " ('go', 49),\n",
       " ('without', 47),\n",
       " ('first', 45),\n",
       " ('still', 45),\n",
       " ('want', 44),\n",
       " ('like', 43),\n",
       " ('see', 42),\n",
       " ('hand', 41),\n",
       " ('made', 40),\n",
       " ('make', 40),\n",
       " ('head', 39),\n",
       " ('much', 39),\n",
       " ('come', 39),\n",
       " ('day', 38),\n",
       " ('thing', 38),\n",
       " ('move', 38),\n",
       " ('chief', 38),\n",
       " ('thought', 37),\n",
       " ('clerk', 37),\n",
       " ('turn', 36),\n",
       " ('away', 35),\n",
       " ('samsa', 34),\n",
       " ('let', 33),\n",
       " ('bed', 32),\n",
       " ('well', 32),\n",
       " ('went', 32),\n",
       " ('famili', 32),\n",
       " ('left', 32),\n",
       " ('seem', 31)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_freqdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAElCAYAAAD+wXUWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXl8VOXV+L8nG9mAEMIS2TdRxI0EF8TWvdraWq3a2tZqN7vY1tYutr++favt27fWpdbqW627tlqXFitQF1TADVQSdhUEAUVEMCFsSSDb+f3xPENuJncyk5BhAnO+n8/9zNx7z5z73Jk799znnPOcR1QVwzAMw4gmI9UNMAzDMHomZiAMwzCMUMxAGIZhGKGYgTAMwzBCMQNhGIZhhGIGwjAMwwjFDIRhGIYRihkIwzAMIxQzEIZhGEYoWaluwN5QUlKiI0eO7NJn6+vrycvL61ZZ02k6Tafp7Gk6w6isrKxS1QFxBVV1v13Kysq0q1RUVHS7rOk0nabTdPY0nWEAFZrAPdZcTIZhGEYoZiAMwzCMUMxAGIZhGKEkzUCISK6IvC4iS0TkDRG5xm8fJSKvichqEXlERHL89l5+fbXfPzJZbTMMwzDik8wexG7gFFU9EjgKOFNEjgP+ANykqmOBGuDrXv7rQI3ffpOXMwzDMFJE0gyED5bv9KvZflHgFOCffvv9wGf9+3P8On7/qSIiyWqfYRiG0TGiSZxRTkQygUpgLPB/wPXAq76XgIgMA55S1Ykishw4U1Xf9/veAY5V1aoonZcBlwGUlpaWzZgxo9Pt+nBnE+9W1zFmQAEl+Zlx5evq6sjPz+82OdNpOk2n6dxXOsMoLy+vVNXyuIKJ5MLu7QIUAXOAqcDqwPZhwHL/fjkwNLDvHaCkI71dHQfxs8eW6IirZurfX12XkPyBlhdtOk2n6UwfnWHQk8ZBqOpWbyCOB4pEJDKCeyiwwb/f4A0Gfn9foDoZ7elfmAPAlp0NyVBvGIZxQJDMLKYBIlLk3+cBpwNv4QzF+V7sEuAJ/366X8fvn+0tXbdTXOAMRHWtGQjDMIxYJLMWUylwv49DZACPqupMEXkTeFhE/gdYBNzt5e8G/iYiq4EtwBeS1bA9PQgzEIZhGDFJmoFQ1aXA0SHb1wDHhGzfBVyQrPYEKS7oBUB17e59cTjDMIz9krQcSd0/4mKyGIRhGEZM0tNAmIvJMAwjLmlpICJB6i21DSQpDm4YhrHfk5YGoldWJnlZQlOLsr2+KdXNMQzD6JGkpYEA6NvLnboFqg3DMMJJWwPRxxsIi0MYhmGEk/YGwgbLGYZhhGMGwlJdDcMwQklbA9E3N+JishiEYRhGGGlrIMzFZBiG0TFpbyAsSG0YhhFO2hqIvhaDMAzD6BAzENaDMAzDCCVtDUSri8mC1IZhGGGYgbB6TIZhGKGkrYHIyRQKcjJpbFa277J6TIZhGNGkrYEA6F/oJg6yTCbDMIz2pLWBaC37bXEIwzCMaNLaQNjMcoZhGLFJawMR6UFYqqthGEZ70tpAWAzCMAwjNultIMzFZBiGEZO0NhAWpDYMw4hNehuIQotBGIZhxCKtDURJgYtBmIvJMAyjPWltICI9CAtSG4ZhtCetDcSeIHXtbqvHZBiGEUVaG4jc7EzyfT2mHbutHpNhGEaQtDYQAP0jbiaLQxiGYbQhaQZCRIaJyBwReVNE3hCRK/z2q0Vkg4gs9ssnA5/5hYisFpGVIvKJZLUtSHEkUG1xCMMwjDZkJVF3E/BjVV0oIr2BShF51u+7SVVvCAqLyATgC8BhwEHAcyJysKo2J7GNgcFyNhbCMAwjSNJ6EKq6UVUX+vc7gLeAIR185BzgYVXdraprgdXAMclqX4T+BZbJZBiGEcY+iUGIyEjgaOA1v+l7IrJURO4RkX5+2xBgfeBj79OxQekWbLCcYRhGOJLs9E4RKQReAH6nqtNEZBBQBSjwW6BUVb8mIrcCr6rq3/3n7gaeUtV/Rum7DLgMoLS0tGzGjBldalddXR35+fk8sbKWB5bu4Oxx+Xz1qD4dyiaqszPHN52m03SazmTqDKO8vLxSVcvjCqpq0hYgG3gGuDLG/pHAcv/+F8AvAvueAY7vSH9ZWZl2lYqKClVVfaxivY64aqZe8Y+FcWUT1dmdsqbTdJpO07m3stEAFZrAPTyZWUwC3A28pap/DGwvDYidCyz376cDXxCRXiIyChgHvJ6s9kXoby4mwzCMUJKZxXQCcDGwTEQW+23/D7hIRI7CuZjWAd8CUNU3RORR4E1cBtTlmuQMJrAgtWEYRiySZiBU9WVAQnY92cFnfgf8LlltCqPYDIRhGEYoNpI6UNFVrR6TYRjGHtLeQOTluHpMDc0t7LR6TIZhGHtIewMB5mYyDMMIwwwEwbLfZiAMwzAimIGgtQdhM8sZhmG0YgYC6F/oAtVbaq1gn2EYRgQzEJiLyTAMIwwzEASC1OZiMgzD2IMZCAIxCOtBGIZh7MEMBFBSaLPKGYZhRGMGguA4CAtSG4ZhRDADgcUgDMMwwjADQWvJ76paq8dkGIYRwQwEkJ+TRV52Jg1NLdQ2JL3CuGEYxn6BGQiPuZkMwzDaYgbC0zqznAWqDcMwwAzEHqwek2EYRlvMQHgiEwdZyW/DMAyHGQhPq4vJDIRhGAaYgdiDDZYzDMNoixkIj8UgDMMw2mIGwlNiLibDMIw2mIHwFFuQ2jAMow1mIDz998QgzEAYhmGAGYg9RGIQVTt3Wz0mwzAMzEDsIT8nk9zsDHY3tVBn9ZgMwzDMQEQQERssZxiGEcAMRACbetQwDKMVMxABWsdC2GA5wzAMMxABrNyGYRhGK0kzECIyTETmiMibIvKGiFzhtxeLyLMissq/9vPbRUT+LCKrRWSpiExKVttiYamuhmEYrSSzB9EE/FhVJwDHAZeLyATg58DzqjoOeN6vA5wFjPPLZcBtSWxbKDZYzjAMo5WkGQhV3aiqC/37HcBbwBDgHOB+L3Y/8Fn//hzgAXW8ChSJSGmy2hdG/8BYCMMwjHRH9sWgMBEZCbwITATeU9Uiv12AGlUtEpGZwLWq+rLf9zxwlapWROm6DNfDoLS0tGzGjBldalNdXR35+flttlV8sIvfv7KVowfn8F8nFncom6jOvZU1nabTdJrOvZWNpry8vFJVy+MKqmpSF6AQqATO8+tbo/bX+NeZwNTA9ueB8o50l5WVaVepqKhot23hu1t0xFUz9dO3vBRXNlGdeytrOk2n6TSdeysbDVChCdy/k5rFJCLZwL+AB1V1mt+8KeI68q+b/fYNwLDAx4f6bfuMyEA5K/ltGIaR3CwmAe4G3lLVPwZ2TQcu8e8vAZ4IbP+Kz2Y6DtimqhuT1b4wivekuVoMwjAMIyuJuk8ALgaWichiv+3/AdcCj4rI14F3gQv9vieBTwKrgTrgq0lsWygFOZn0yspgV2MLdQ1N5Ock8+sxDMPo2STtDqgu2Cwxdp8aIq/A5clqTyK4ekw5fLBtF9U7G8gvNgNhGEb6YiOpo4i4mWwshGEY6Y4ZiCgig+UsDmEYRrpjBiKKkj0F+6wHYRhGetNpAyEi/UTkiGQ0pidQbPWYDMMwgAQNhIjMFZE+IlIMLATuFJE/xvvc/ojFIAzDMByJ9iD6qup24DxcvaRjgdOS16zU0VqPyQyEYRjpTaIGIsuPer4QVxLjgKV12lELUhuGkd4kaiCuAZ4BVqvqAhEZDaxKXrNSh7mYDMMwHImOBNuoqnsC06q65kCNQfS3eakNwzCAxHsQtyS4bb+n2NJcDcMwgDg9CBE5HpgCDBCRKwO7+gCZyWxYqijslUVOVgb1jc3UNzSTl3NAnqZhGEZc4vUgcnDzOWQBvQPLduD85DYtNUTqMYGNpjYMI73psAehqi8AL4jIfar67j5qU8opLshhoy/YN7Rf12ZsMgzD2N9JNEjdS0TuAEYGP6OqpySjUanGRlMbhmEkbiAeA24H7gKak9ecnkFJYaRgnxkIwzDSl0QNRJOq3pbUlvQgWnsQFoMwDCN9STTNdYaIfFdESkWkOLIktWUpxFJdDcMwEu9BROaQ/mlgmwKju7c5PQMbLGcYhpGggVDVUcluSE+if2GkHpMZCMMw0peEDISIfCVsu6o+0L3N6RkUWw/CMAwjYRfT5MD7XOBU3LwQB6SB2ONi2mlBasMw0pdEXUzfD66LSBHwcFJa1AOwiq6GYRhdn5O6Fjhg4xK9e2WRk5lBXUMzuxoP+GEfhmEYoSQag5iBy1oCV6TvUODRZDUq1YgIxQU5fLh9l8UhDMNIWxKNQdwQeN8EvKuq7yehPT2GPQbC4hCGYaQpCbmYfNG+FbhKrv2AA/6xun+hZTIZhpHeJGQgRORC4HXgAty81K+JyAFZ7jtCJJNpi42mNgwjTUnUxfRLYLKqbgYQkQHAc8A/k9WwVFNc0DpYbmRBihtjGIaRAhLNYsqIGAdPdSc+u18ScTFVWcE+wzDSlERv8k+LyDMicqmIXAr8B3iyow+IyD0isllElge2XS0iG0RksV8+Gdj3CxFZLSIrReQTXTmZ7qTYXEyGYaQ58eakHgsMUtWfish5wFS/az7wYBzd9wG30n609U2qGsyKQkQmAF8ADgMOAp4TkYNVNWWDEPq3mTTogO4sGYZhhBLvzvcn3PzTqOo0Vb1SVa8EHvf7YqKqLwJbEmzHOcDDqrpbVdcCq4FjEvxsUrAsJsMw0h1R1dg7RRao6uQY+5ap6uEdKhcZCcxU1Yl+/WrgUpzRqQB+rKo1InIr8Kqq/t3L3Q08partguAichlwGUBpaWnZjBkz4pxiOHV1deTnx55v+oMdTXz/6SoGFmRy40kFHcomqrMrsqbTdJpO07m3stGUl5dXqmp5XEFVjbkAqzrYt7qjz3qZkcDywPog3EjsDOB3wD1++63AlwNydwPnx9NfVlamXaWioqLD/VvrGnTEVTN1wq+eiiubqM6uyJpO02k6TefeykYDVGic+6uqxnUxVYjIN6M3isg3gMr4dqqdMdqkqs2q2gLcSasbaQMwLCA61G9LGX1ys8jOFGobmmlojt3LMgzDOFCJNw7ih8DjIvIlWg1COZADnNvZg4lIqapu9KvnApEMp+nAQyLyR1yQehxuYF7KiNRj2rR9N9t3t6SyKYZhGCmhQwOhqpuAKSJyMjDRb/6Pqs6Op1hE/gGcBJSIyPvAr4GTROQoXOG/dcC3/HHeEJFHgTdxtZ4u1xRmMEUoLujFpu272WYGwjCMNCTR+SDmAHM6o1hVLwrZfHcH8r/DxSV6DJFUV+tBGIaRjliCfwdEUl2tB2EYRjpiBqIDiq0HYRhGGmMGogMiLqZtu8xAGIaRfpiB6ID+ha6iq/UgDMNIR8xAdIC5mAzDSGfMQHSAZTEZhpHOmIHogEgPoqq+mcZmMxKGYaQXZiA64KCiPIoLcthS38J3/l7JrsaUj90zDMPYZ5iB6IDc7EzuvXQyhTnCc29t5uv3L6B2d1Oqm2UYhrFPMAMRhyOHFfHbk4opKezFK6ur+co9r7OtvjHVzTIMw0g6ZiASYHjfbB779vEc1DeXyndr+OKdr1K90+aqNgzjwMYMRIKMKingse9MYWT/fN74YDufv+NVNm3flepmGYZhJA0zEJ1gSFEej377eMYP6s3qzTu54Pb5rN9Sl+pmGYZhJAUzEJ1kYO9cHr7sOI4Y2pf3ttRxwe3zWb15Z6qbZRiG0e2YgegC/QpyePAbx3LMyGI+3L6Lz/91Pm9+sD3VzTIMw+hWzEB0kd652dz/tWP42MEDqK5t4At3zOft6oZUN8swDKPbMAOxF+TlZHLnV8r4xGGD2L6riWteqOHm51ZRZRlOhmEcAJiB2Et6ZWXyf1+cxHmThrCrWbnpubeZcu1sfvrYEt7aaG4nwzD2XxKactTomKzMDG684EiO6F3Hy5tzeH7FJh6rfJ/HKt9nypj+fO2EUZxyyEAyMiTVTTUMw0gYMxDdhIhw+MBeXHpWGeuqarlv3joeq1jPvHeqmfdONSP753PplJGcXz6Mwl72tRuG0fOxO1USGFlSwNWfOYwrzziYRxes575561hXXcfVM97kxllv8/nJw5jc1wr/GYbRs7EYRBLpk5vNN04czQs/PZnbv1zGMaOK2bG7ibteXssVz1Tx70UbUt1EwzCMmJiB2AdkZghnThzMo986npnfn8rpEwaxq0n54SOL+fGjS6xCrGEYPRIzEPuYiUP6csfFZXy7rA+52Rn8a+H7fPqWl1m+YVuqm2YYhtEGMxApQEQ4fXQ+M743lUMG92ZNVS3n/WUed7+8FlVNdfMMwzAAMxApZdyg3vz78hO4+LgRNDS38NuZb/L1+yuslLhhGD0CMxApJjc7k99+diK3f7mMvnnZzF6xmbNufol571SlummGYaQ5ZiB6CGdOHMyTV5zI5JH92LxjN1+66zVueGYlzS3mcjIMIzXYOIgexJCiPP7xzeP48+zV3Dp7FbfOWc0zxdl8dudqRpUUMKqkgJH9C8jLyUx1Uw3DSAOSZiBE5B7gbGCzqk7024qBR4CRwDrgQlWtEREBbgY+CdQBl6rqwmS1rSeTlZnBlacfzJQx/fnhw4tZtWUX1z+zso3M4D65zliUFDDav44qyae+sQVVxX2dhmEYe0cyexD3AbcCDwS2/Rx4XlWvFZGf+/WrgLOAcX45FrjNv6Ytx43uz9M/PJHb/vMazXn9WVtVy9rqWt6rruPD7bv4cPsu5q+pbve5nBlP0zc/m3752RTl5VCUn02//ByKCtx6v/xstm3axdgJjfTNy07BmRmGsb+QNAOhqi+KyMiozecAJ/n39wNzcQbiHOABdTmer4pIkYiUqurGZLVvf6AoP4czRudTVjZhz7am5hY2bK1nTVUt6/yypqqWddW1bNpWT0NzCx/t2M1HOzrOhLpu/rOUj+jHKYcM5JRDBjJ2YKH1PAzDaIMkM+/eG4iZARfTVlUt8u8FqFHVIhGZCVyrqi/7fc8DV6lqRYjOy4DLAEpLS8tmzJjRpbbV1dWRn5/frbI9QWdmrzx2NrSwY3cLOxpa2Nmg/tVt29mgbNjewKqaZoLx74H5mUwq7cWk0l5MHJhDr0xJajtNp+k0nftGZxjl5eWVqloeV1BVk7bgYg3LA+tbo/bX+NeZwNTA9ueB8nj6y8rKtKtUVFR0u+z+pHNrbYPOWLJBf/TIIp30m1k64qqZe5bx//WkfvXe1/WBeWv12ZdfS2k7TafpNJ17LxsNUKEJ3MP3dRbTpojrSERKgc1++wZgWEBuqN9mJIm++dmcfcRBnH3EQbS0KEve38qcFZuZs/Ijlm3YxuwVm5m9YjM5GXBxzZt856QxlBT2SnWzDcPYh+xrAzEduAS41r8+Edj+PRF5GBec3qZpHn/Yl2RkCEcP78fRw/tx5Rnj2bx9F3NXfsTTb3zI7BWbufvltTz02ntcMmUk3/rYaPoV5KS6yYZh7AOSNlBORP4BzAfGi8j7IvJ1nGE4XURWAaf5dYAngTXAauBO4LvJapcRn4F9crlw8jDuuXQy15/Wn9MOHUh9YzO3v/AOU/8wmxtnrWRbXWOqm2kYRpJJZhbTRTF2nRoiq8DlyWqL0XVG98vmrtPKWLx+Kzc9+zYvvP0Rt8xezX3z1vGNqaP52tSR9M61dFnDOBCxUhtGQhw1rIj7v3YM//z28UwZ058du5q46bm3OfG6Ofxl7mrqm1pS3UTDMLoZK7VhdIrykcU89M3jmP9ONX98diUL1tVw3dMrKcgWjljyatTo7gKGF+eTk2XPIYaxP2IGwugSx4/pz6Ojj+fl1VXcOOttFq/fyvw11e1Gd2cIDOmXx6iSQkb1z2dUSQEF9Y1MspIghtHjMQNhdBkR4cRxA5g6toQnX3ydgsGjWFdV68uC1LGuqpb3a+pYv6We9VvqeTHw2b8ufZHzJg3hs0cN4aCivJSdg2EYsTEDYew1IsLgwizKxg+E8W337W5qZv2W+j2GY/XmnTy1bAOrN+/kuqdXcv0zKzluVH/OmzSEsw4vpbCXXZKG0VOwf6ORVHplZTJ2YCFjBxbu2XbeiAZ2Fg5j2sINPPvWpj2uqV89sZxPHDaYc48ewtSxJSlstWEYYAbCSAFZGcKphw7i1EMHsa2+kSeXbeTxhRt4fd0Wnlj8AU8s/oABvXtxfGkmB42tp7SvuaAMIxWYgTBSSt+8bC46ZjgXHTOc9VvqeHzRBqYtfJ911XVM3wFPXz+XLx4znO+ePIaBvXNT3VzDSCss/9DoMQwrzucHp45jzk9OYtp3p3D80Fwamlq4b946PnbdHP73ybeo3tlxGXPDMLoPMxBGj0NEmDS8Hz85voinrjiRMyYMYldjC3e8uIYTr5vDdU+vYGtdQ6qbaRgHPGYgjB7NoaV9uOMr5cz43lROOWQgdQ3N/GXuO0z9wxz++OzbbKu3mlCGkSzMQBj7BYcP7cs9l05m2nencOK4EnbubuLPz6/ixD/M5tbZq6jZ1RyZS8QwjG7CgtTGfsWk4f3429eP5fW1W7hx1kpeW7uFG2a9DUDvWbP2lPhoU/KjfwF9862goGF0FjMQxn7JMaOKefgyVxPqL3PfYeG71ezY3cSyDdtYtmFbO/nighxG9s+nf9Zufj58J2MGFIZoNQwjiBkIY79FRJgytoQpY0uoqKhg1CGHuzIfVbWsq/YlP6pcyY8ttQ1sqXWB7Tk3vchXTxjJD04dZ6XKDaMDzEAYBwQiQv/CXvQv7EX5yOI2+1SVTdt3s7aqlrueW8LsdfXc+dJaHl/0AT87czznTxpKRoYVDjSMaCxIbRzwiAiD++Zy/Jj+fLe8L9Mvn8qk4UVU7dzNz/65lHNvm8ei92pS3UzD6HGYgTDSjsOH9uVf35nCTZ8/koG9e7Fk/VbO/cs8fvzoEjZv35Xq5hlGj8EMhJGWiAjnHj2U2T85ie+cNIaczAz+tfB9Tr5hLn994R0abIY8wzADYaQ3hb2yuOrMQ5j1o49x2qEDqW1o5vdPreATf3qRl96rZ1djc6qbaBgpwwyEYQAjSwq465LJ3PfVyYweUMDaqlr+9No2Jv/Pc1z1z6W8tqaalhYbiGekF5bFZBgBTho/kCljSnikYj33vbCCd2qaeKRiPY9UrGdIUR7nTRrCuUcPYbSNozDSADMQhhFFTlYGFx83ggnZVfQddjDTFm7g34s2sGFrPbfMXs0ts1dz1LAizps0hLOPOCjVzTWMpGEGwjA6YOzA3vzszEP4yRnjeXVtNdMWbuCpZRtZvH4ri9dv5Tcz3uTowTlc0LKek8YPYGAfm7PCOHAwA2EYCZCRIUwZU8KUMSX89pyJzHrzQ6Yt3MBLqz5iwQe7WfCvpQBMHNKHU8YP5ORDBnLk0CIbgGfs15iBMIxOkpeTyTlHDeGco4awefsu7nxqAe/U5/LK6iqWb9jO8g3b+fPs1fQvyOHjBw/g5EMG8rGDB9A3z8p6GPsXZiAMYy8Y2CeXM8fmU1ZWxq7GZua/U82clZuZvWIz79fUM23RBqYt2kBmhlA2oh8lmbt4uWYVRfnZFOVn0y8/p81rYa8sRKzXYfQMzEAYRjeRm53JyYc499I1n1FWb97J7BXOWFS8W8Pra7cA8OTqt2PqyMoQivKzyZVmBr8+j6L8HPp5Y+Le57QxLv3yc2i2eTCMJGEGwjCSgIgwblBvxg3qzbc+PoZt9Y3Mf6eKV5etorB4EDV1DWytb2RrXQM1tY1sq2+kpq6BuoZmqna6qrPv70isPlRuljBp0ascPbyIo4f146jhRZQU9krm6RlpghkIw9gH9M3L5syJpQzY/QFlZeNjyu1uamZbXSOvVCymdOQ4ttZ5I1LXyNb6BrbWutcav31LbQNVOxuY9041896p3qNneHE+k4YXcfTwfhw9vIhDBvfZF6dpHGCkxECIyDpgB9AMNKlquYgUA48AI4F1wIWqaiU2jbSiV1YmA/tkMrxvNmWj+yf0medeeZ2WouEsWr+VRe/VsGT9Nt7bUsd7W+r49+IPvN4MhvXOZMSyBe3cVsEYSGSfYUBqexAnq2pVYP3nwPOqeq2I/NyvX5WaphnG/kO/3EzKDhvMGYcNBqCpuYW3N+1k0foaFr67lUXra1jzUS2ra1pYXbM5IZ2F2cLYV19x07f2L2DUADd168iSfJtkKY3oSS6mc4CT/Pv7gbmYgTCMTpOVmcGEg/ow4aA+fOnYEQBsrWtg5kuVDBw6iq11je1iIDV1DXviIDV1jexsbNkzGDCaksJejCrJZ1RJAVK/k/nbViXUrp3VdTT2q2ZUSQEDe/eybK39ANEUZECIyFqgBlDgr6p6h4hsVdUiv1+Amsh61GcvAy4DKC0tLZsxY0aX2lBXV0d+fn63yppO03kg6FRVNtbUUtOcw8YdTWzc2cwH/vXDnU00dkMl9NxMobR3JoMLsygtzOSg3u61tHcWWU31FBQUJKRnf/g+U60zjPLy8kpVLY8nlyoDMURVN4jIQOBZ4PvA9KBBEJEaVe3XkZ7y8nKtqKjoUhsqKyspKyvrVlnTaToPdJ0tLcoH2+pZV1XH2upaFq9cy+DBg+Pqa1F4a+0Gtmsua6tqqalrjClbkC2MHdTHubdKChjll5ElBfSJcm/t79/nvtAZhogkZCBS4mJS1Q3+dbOIPA4cA2wSkVJV3SgipUBizlLDMPYZGRnC0H75DO2Xz9RxJUzIrqKs7JCEPltZWbvnhra1roG1VbWsq65l7Ue1rK2uY11VLWuratm5u4kl729jyfvb2ukoKcxhZP9Ww7F1cx1vNqyLe+z319fxYfZG+uVn0zcwhiQ3O8NcXR2wzw2EiBQAGaq6w78/A/gNMB24BLjWvz6xr9tmGMa+oSg/h6OH53D08LZOAlVl9rwF9Bky1hsOZ0DWVbulaqdL6614N5DguOiNxA66cGG7TTlZGfTzBqNvnnttqtvGuI9WUJTXPrsrkvWVnZkeU+mkogcxCHjcW+0s4CFVfVpEFgCPisjXgXeBC1PQNsMwUoiIUJSbSdnIYiaPLG6zr6VF+XD7LtfTqK5lXVUt733wIQMGDIir98NNH5GV39eNJalrDcY3NLWwaftuNm3f3Ub+ubXvdKgjIumeAAAfFUlEQVSvsFcW+ZnKwHkveSOS4w1KeOrwjoYWWlp0vyveuM8NhKquAY4M2V4NnLqv22MYxv5BRoZwUFEeBxXlMWVsCQCVlfWUlR0e97Ox/PX1Dc0uoyswIHHpitX0GVBKTW0g08vv31rXyNb6RnbubmInsLlue8Ltl+lP7umlFOVnB3ooEYOSTc2meur6fNSmRld+TmbK3GA9Kc3VMAxjn5KXk0lejjM6EQY3fkBZ2diYn1FVduxu4qXXFjJ09PjWFOHagCGpb9zzvqaugeodu6hrVG+IYgfoAXj19TarOZkZPm6STVFeq+HIbailizHqhDEDYRiG0QlEhD652QwuzOLIYe0y8UOprKzkiKOOZlt9Y9vyKXUNbcalrN2wCXIK24xL2dXYwkc7dvPRjrZusIOLkz9g0QyEYRjGPiA7M4OSwl4dFlKsrGxo5wrb1dgciJs07OmFVG18L9lNNgNhGIbRk8nNzmRw30wG9207nW1l5UdJP3Z65GoZhmEYncYMhGEYhhGKGQjDMAwjFDMQhmEYRihmIAzDMIxQzEAYhmEYoZiBMAzDMEJJyXwQ3YWIfIQr7NcVSoCquFKdkzWdptN0ms6epjOMEaoav8qhqqblAlR0t6zpNJ2m03T2NJ17s5iLyTAMwwjFDIRhGIYRSjobiDuSIGs6TafpNJ09TWeX2a+D1IZhGEbySOcehGEYhtEBZiAMwzCMUMxAGIZhGKGkjYEQx7BUt6O7EJEMEZmSwuMfUN+nYRjtSRsDoS4a/2R36RORSR0tIfJfD9l2bVePr6otwP8l2NZMEflRd8n543fq+xSRKxLcNipk2+REj7M3iMg0EfmUiMT9X6SynYHj5YnI+DgyYe1sty3ViMgJCW5L6DpKxrGj9ufvzTG9jvM6WmIdV0R+JSJ3+vVxInL23rYlZhvTKYtJRO4HblXVBQnIng38FhiBm5pVcPfFPn7/HC+aC5QDS7zMEbgRjsdH6XsSeFBVH/Tr/wfkqmqY4RgAfBMYSWBaWFX9WpTcDcB8YJrG+SFF5HVVPSaB805Izst25vtcqKqTorYtUtWjo+WAT6vqBr/+cX+Mw6PkDgZuAwap6kQROQL4jKr+T8ixE5IVkdOArwLHAY8B96rqyljnk2A7RwHfp/1v+ZkQnScAV9P+mhsdIvtp4AYgR1VHichRwG+i9cb43itVtcy/nwHEvHaC+kTkylhyXvaPUcfp68/nRL/pBd/GbSHnE9bORLe1uY5EZFmMc4p8n0d05Th++xTgLqBQVYeLyJHAt1T1u1Fyca85EbnXvx0ITAFm+/WTgXmq2u7GLyKPAJXAV7zefC97VMj57jXpNif1scCXRORdoJYYF4znT8B5wLKwm6+qngzuqROYpKrL/PpE3J8ims8B00WkBTgT2BpmHDxPAC8BzwHNHZzPt4ArgWYRqQ+cT58Q2VdE5FbgEdy5R85jYRflIIHvU0QuAr4IjBKR6YHP9ga2xDinf/sb4CTg98AnQ+TuBH4K/NW3b6mIPAS0MxCJyqrqc8Bz/sZ2kX+/3n/+76ra2IV2/hu4G5gBtITsD3I38CPcDaCj3x3cNXYMMNe3fXGwZyAihwCHAX2jnkb74B5qItzgX88DBgN/9+sXAZuijtm7g/aE3ZDvAZYDF/r1i4F7/bEi7Twed3McEGWA+gCZAblY11Ef2l9HCT1RJ3rsKG4CPgFMB1DVJSLysRC5uNecqn7Vt2MWMEFVN/r1UuC+GMcfo6qf998HqlonIpLA6XaJdDMQn+iE7Hpgebwnc2B8xDgAqOpyETk0si4ixQHZb+BuGK8A14hIsaqG3STzVfWqeA1U1Y7+sNFEnjB+E1QBnNJFOUjs+5wHbMQVFrsxsH0HsDRaWFUXiMgPgFnALuA0VQ2bnT1fVV+P+m80xWhDwrIi0h/4Mu5mtgh4EJgKXAKc1IV27lLVP8doVzTbVPWpBGUbVXVb1DkFr9XxuBtlEfDpwPYduN6p+4DqCwAicqOqlgfkZohIRRvlqtd42RNU9ZXgvhgumTGq+rnA+jUisjhKJgcoxN2LgtfzduD8wHrC15GqJlrAM9Fjt0FV10d972HGvDPX57CIcfBsAobHkG0QkTz8by0iY4Ddsdq6t6SVgVDVd32XMNLlfUlVl8QQ/xnwpIi8QOAHiO5GA0tF5C5an7y+RNsLtpK2f1wBPuUXBdq5D4CZIvJJVe3Qx++fHL4EjFLV34oLGpeq6uvRspEeTzwSlfOy74rIVGCcqt7rXWOF0TLAuyLyJeADVd3l254HDAXW+fVoV0c+sA24W0TCXDJV/s8R+aOcj7uBhJGQrIg8jrux/g3nPorIPBK5WXahnTeLyK9xhiR4HYX1yOaIyPXAtARk3xCRLwKZIjIO+AHuJhr5zBPAEyJyvKrOD/l8NAUiMlpV1/jzHAUUxJC9BddriretXkSmqurLXucJQH1QwBuoF0Tkvo5u7IHr6DSgXlVbvBvnEGBZUFZEdtCxi6lPZ44dxXrvZlIRyQauAN4KkevM9fm8iDwD/MOvfx7nPQjj18DTwDAReRA4Abg0wbZ3mnSLQVyBe3qa5jedC9yhqreEyM4CduIuvj2ugchTVEAuF/gOEOlmvgjcFrkRepkM4Pjop64O2rkD9+ds8Euo60hEbvNtO0VVDxWRfsAsVW0XLBWRQcD/Agep6lkiMsG36e4oub64izByPh35jX+Ni7+MV9WDReQg4DFVDQv6VQBTVLXBr+cAr0TaKs6HH5PIk25A32hcqYEpQA2wFviyqq4LOXZCsiJysqrOif58lExn2/l7XG/kHVqvI1XVdj0yaY1rRakMlc0Hfgmcgbs+ngF+G7zuvFyi8Zczcd/RGq9vBM63/kxAJuKS+SHO1RKhD3Cuqh4ZpfNI4AGgr99UA1yiqu16jv7cw1y5p0TJVeIe8PrheuILgAZV/VL0ZxPFf0c/oX2cKOx7LwFuBk7DfU+zgCtUtTpKLuHr08ufR+uD64uq+ngH7e2Pi5MJ8KqqdrXkd1zSzUAsxd0Ua/16ATA/LAYhIstVdWI3HrtdQLYbdC5U1UlB3SKyJPqP6rc/hfP//lJVjxSRLGCRtg+q/gvnN77fb7oYOFJV22VVeHfB0cDCwPGXxvg+F2tUIC2srf7JdWNUT2NQB3+sAiBDVXeE7e+srLgY0gQCfnpVfSCG7CAgYoxfV9XNITKrcf7lhnjt6yoikgkUqOr2kH0v4H3hgd8o9NoWkV64J3KAFaq6O2r/x3Futm8Dtwd27QBmqOqqKPmIXz/Sq9yJ621VquriKNmywGouLmbXpKo/i5KLXPPfB/JU9broa0tE+qjqdmnr3t1DtFtXRJb482kT+1HVyujPSohbWERGqerasGN15vrsCAnJjAwSo5e516SViwlncYP+wma/LYwnReQMVZ0Vqih2pgQAITfJ50XkcySWcZSo66jR3xwi3dgBxA6ElqjqoyLyC9++JhEJ850m4jeO0KCqKiKR48dySQB8JCKfUdXpXvYcwic7eQz31BWh2W9r0yvyN7PP4Z/6xPt6VTUYO4nIFgFfCZH9QZTcr3E3wAm4FN6zgJdxT8HROi8ErscFiQW4RUR+qqr/jBJdjosDtDMeIToT6uV52YdwN+pm3FN0HxG5WVWvjxLt0BcuIqeo6mxpn1Y5xrvMIr3toEumXlWvi2rPBcCqKB3lfpmO+44i7tdvi8hjQR0hN+NXRKSdq9QdSo73uiJJHtEB5Ydw8ZeIezd48mFu3SZVvS3kWGHMEJGzIsZYXLzxMaCNwe3kb3ke8AdcNpMQ7jGIxF1CsyaBNlmT3YYmecKJnrTgMn6W4DJArgYWAz+MIbsDd7Pd5d/vALYH9o/oaOlAXyMuCNZGX5TsbbgxDm/59X7AghC5L+H+fO8DvwNWAhfE0DkX6I972gfXRX0hRG4+MDWwfgKulxWm8ye4LI01ONfdfOD7MWTHAK/igv/v4fzlY0PkFodsWxKy7WlcptXPgB9HlhjHngf8EZfCeklkCZFbhhsbtMSvDwKejaFzCTAwsD4gRjvn4rJsnvG/1XRgegydT+EyfiLHz8Jl0YXJLg5cAzcC2cDSGDrHBH7384GnAvuv8a/3hiz3xDj2wgS3vYhLB42sF+JclnnAm1GyxYGlBJcAsTJE58f8d3iVXx8N/Lmj/328BXcv+C5QGmxHDNlP+XMoBMqAN4Cj9vK3XA0cmmBbpwGHB9YnAv/cm/Pv8HjJUtxTF1wg7Qd+OTrV7YnRxsifeVFgW7ubj99+CHA58L2OLjJ/3q/guvivAG/jXEfRckf5m9863HSui4AjOtB7Ou5J+gbg9ATOrTB40wjZ/yzORx5ZPwd4PkRueWe/zwTkFvjXSpxfXXCuljDZZVHrGWE3AOB14OOB5STgtTjHD/7u7Qym3/4Gzig8BnzcbwszEKNxAc86YAOuRzSii9flWbhg9Cbgz4HlPpyLLVp+BZAdWO8V+T6D5+jX1+IeNNbieiKzCDyoeJlM4IZOtDfsugnbtjZkWdOB3s/iHjqWAQd3w2/5SifO6Y1EtnXXklYuJu+TXOeXyLZsbZvfHpT/DK3B2rmqOjNEJpgxkYP709ZqyFiERPR5OuM6WoXrkWR52eGq+l6I3Bu4G9R43I1vJSEj6dX5ho8UkUimRzu/dpT8s7ibeod0osv9beBBcWMxBNfj+EqIynkicrgGUow74G8i8k1gJm2zg6JTjBd4d9SdOCOxE9crCuNpaZ95EpZ1lqXtA9d5MXTW+gBk5Hc/DmfQw7gddyNbCrwoIiNiyH7Wt2sO7veuBU4TN1guOg7wKdzYiWD8Jeiy+wDnzvgM7vuJsAM3fiOaB4HXROQJv/5p4CHvinwzKKiqcUd3q2qzuKy5DhGXOJIPlIhL3Ii4mPoAQ0L0xj22iNxCW5dyX1ziwfe8K+4HUR/pzG9ZIW4A3L9pe31OC5GNlzXZraRbkHodMAyXVSA43/CHuCeib2rADyquDMZk3EUObuBQhar+ogP9gnviPU5Vfx61L2F94lJCP4976r8f5xb4L1V9LEru+7iMo020xlNUw4PEiY5K7UwWUyK+04hsQkHygHwhTtnOGPvfBMbhnjp3xzn3y3EuuK20/slVo0Yoi8jf/fm+hHMt9tGQjJuo84/csF7SQOaJiHwH57YYjbuRROiNe2L8coi+Sbgn9Im42MUA4PywNvh4SQTF3fwzVfVXUXIP0TYOcDbuhjISl3F2nZe7HXdTPRk3Uvh8XK8gbKR/lqrGyumPli3HuSnx510RQy6bttmAc3GB9cYoudtwN/nHaDuQc1pA5gpcptVBuF6T4L6jHbisxXYlauIlJ4jIJR2dp6reH1zv5G95b7jKtpUTvGzcrMnuJN0MxJ04f90zfv0MXKDzXuBmVT02ILsU51ts8euZuBta2Kjr6OOElZDolD5xI2FPxV3cz6tqu1xrcRkyx2pUil2UzGDcH+rvuJGowaep21X1kCj5zmQxrcaNFwjLA4+WXaCqk6VtxlW7zCa/Pd6TLP6JuR+B1EDc6PR2+ewisgY4RuOkA4rIyV7fiTi//SJcyuHNMeQH4UYzK1FZTN7Q9sONsA4+LOwI6bkEdWYR6OV10Lv9cWA1F3fjfyv6piIiLwKfjBhab3j/gxvNX6mqE/z2pap6ROC1EBerODGg61FVvVBiJGgk8t/o4LzvwvW+g9dds6p+I0quMzfT/wb+pC6j6Ve4B67falTGT6zkBFWNOVgugfO5ABd3Goa7xxwL/Cr62D2eZPmueuJCuI94qYb4B3FPWcWB9WLCfbznBZbzgWsJCeomqs/v+zNuzEC885mDc2F0JHOJl9uBq/Uyxy/TgfNC5MOCxN3hO51LYkHy23FZQ+txPZllwN0hclf4fdfgRn0vJXaAfBYumyeRdmb6tv0CF4OJFYO40O+/37d3Le4JcW+uz1xcIsU04F+4p+DcBD/bC+e2jN6eUBwAH0PAJRIc5NuyOkpXqX8dEbbs5bmHBfhD426d0Bn5b0/11/ynCIn/kEByAvBoQHZp9NLVYwd+98uBv+DKk9xD7ASBccA/cS66NZFlb76njpa0ikEAG0XkKuBhv/55YJN/mo/28f8eWCRuAI/gunQ/pz3BMgZNuPjGOSFy/wssFJG5cfSB8+/+l7hKnY8DD2ugay6t+eVrgLki8h9ijPZW1/W9X0Q+p6r/inG8IHFHvwZSIjvjO70SZ5TGiMgr+C53iNwUbX2SvUZEbsRlhETzdZwrLzKm5Q+4eEG7QY84V8Ri/1sG2xmd5vo8boDifJybabKGjG3w/DK438eJnsP9ebvKAzhDHjmHL+JGdV+QwGfzcSPTo0k0DjDDx1+uBxbiegh3BhWpH1muiY867gzNIjJGVd8BEDfQbE8atoj8TN2Yh+hYQKRt0TEAAp//FHCnqv5HRMJqde1SNzK7ycfeNuOe/INEKsYmWjk10WOD+41X4DK3foOLK8Tqld+Le3C6CecO/CpJrMqdbgbii7gv99+4i+wVvy2T1oJiAKjqP/zNPJJ/f5WqfhitUH3BrQQ4G/dkUIMzIqH6vM7ITb0Y1z39g7jg8zgvEqkb855fcvwCscdmDPUX/w7cH38S8HNtP87j28AD3kWCb2+0/zVoFOtwo3n3NJ/WkerBc1oobqBVPPdJxBjViRuZXY1LP4ymM2Na/u2XeCzFpS5OxAUUt4rIfFWtD5HNiDIe1ez9H3WiepePZ46PtbQjys2TiTO47caAqBtH8xStcYBvBx42gqOPV+BcOv8Sl0AwiajvTBIsYdFFfoo73+BI7uB/6yrgOlw8pyZBnRtE5K+4TLs/iBs7E/YbxU1O6IJxTPTY4NK9LxCRc1T1fh83eimGbJ6qPi8i4ttytbjR5f+dYLs6RVoZCHU+6O+LSEHkyTPA6pCPTKY1GKS4ipxtEJGhuCe+yB/wJdzQ+/ejRO/G+bY/g/dvi0hM/7ZnLC6NdQSBJwptLZp2gbYPXMd62vyaqt4sIp/AuXouxj25zPKfC1azfIDWOjy1uLICe4Jr2lqFMm7RNok9EOtgcQPstuD8vZGb/Uz/Z72O1kyZu0LO517ck3EkMPxZ3HfcDo0KIMZCVX/k29wbV9/mXlyF014h4olmMXWGhSJynKq+6ttxLC5rKIzgk2wTsEljBI69QYilJ8KvVPUxcVlCp+DSlm/D+c4jejpTHLJT+JveONwDBLgHiOBI7k3+geGruHhBIhVML8TFWm5Q1a3iqqT+NESuD66XNhc3vqZdckIXjGOixwY3NgrcA8lEXOLMwBiyu8WV7lklIt/DBeELY8juNekWpE6olruXDcs6WqCq/y9K7lncyM2/+U1fBr6kqqeH6Mz0Ok/GPanXa1SQ2Mtdh7vhrcG5w/6tqltD5DpTxz4SfLwZ56t+PCpgHMmKGe/b+ATu4v80zj8dlnUT9/gico2q/jpGcBGcscqLfF/iUkC/gzOmijO4oVka4jJFgllEi6L2dxRUVW1f5uN7/rhluF7eS17vbEIQNzJ+z4OBdlA/JxFE5C3c9/+eb+8IXDpyEzEytLqLyLUgrnbUMlV9SJJQHiZOG6bQvh7SA37f92nNCtsQ/BghGWmdPG6nkhO6GxH5Bi7mdDhuTEkhzmD/NUR2Mu5hsQg3X00f4DpVfS0pbUszA/Eazu89XePXpUko60jCawyFbYv2b78cy78tIt/FdXNHqupvRGQ4MFh9qQ0ROQs398CFuNHEEfrg6v60m/DH36CHAKOAI3FuibnqJ44JyL0IfEp97Rj/NP0fVf1YQKZTRdviISJ3q0+nFJFHcW6wSJ73F4G+qnphrM93oLdUVTd6ncGnN8H9qS6Mkv8J7repjPU0nkwkRmZWZH+SfP+RY8/E3XhPx7mX6nEPBp36Lffi+H/D3ZwX0+o61JA40W2q+p0kHD+hh7dkIG3LxmT7zarhZWPKcfGvEVGySXl4SCsXEyRcyz1CEa2TkfSNIVMtIl+m1dVwEc4fHU1n/NuH46u04vzKO3BPGJF4SGcHLIEL6h6Fy3ioEzeIJyx+MghXQTZCg98WpNN19KWD8RXaNtc+YT98PLS1XPfY6JuruDTiaPkbordFk2Q//Gdxc4ZM8/r+hgtwhgXeu5vOuESSQTnu4abDJ9YkGYfOJCckgyfwRQyJP7fDg7jfpU2V6WSRbgYioVru4izIDSSWxfQ1XAziJtyNYx4h9dk76d8+Vn2VVv/ZGnHlsSO6lgBLROShGIHe4LkcoqoraJ0IaLR0PAHVA8DrUb79+6LOpU0dfYkzqM0Td3YxT2f88B0igcFqvkcYoTcuQaHTJNMPT+cys7oVVa0jkFzgjWus+QuSwXLc/2FfHjNCZx7eksFQVT0zQdmP1Be83Bekm4spoVruXnYZLjsnWM65XdaRuHmZf6iqNX69GPcUFj1gKWH/tneFTcHFPCaJS6GcFe0P9kG939N+BOjogMwdqnqZtNbbj4wqjciG1byfRNva9IuiZbzcRNxTbqSschWuCN7yENkOXXGBOEE27f3wK6J6FQkhXRyslir8dzBZW0ud5+KugdDR5gcC0joBU2/cQ8zrtE1Fbjd3dxLbEnl4+wnOpRv28JaM494B3KIJlI0RkVNxXorniZ9avtekTQ/C+xgv1sQnFlmIs+zxrPUREeMArr6PiIQF9nJxFUUT8W//GTf+YaCI/A5faiNELm5OtKpe5t/eBjytUaNKww6ubrRnIiM+7wCuVD/JjoicROskKdHEG1+RaH55wqgrD7IN94faH0g4M+sAIq5bL9mEPLzdQ+w00+48buShKAv4qrgU3w7LxuD+44fgHqT2TEBFSGp5t7QxzXoQCzRktrUYsitwaabv4lI9Q380cZONnBTVg3hhb5/6JLFSG5WqWiYiyyLHi2wLkY1kMU3FGYYbgP/WQHmRLrQxbMKfWBMWJTy7WDoTLzPrQEVE/qBR87CHbUvSsVOSnOCTEmISlpQgIitVdXyYfDJImx6E52VxVUIfoW2hr7Cn5U8kqPNGYL6IRMYjXIArDLdX+LjBijhincmJ7szIzkRZ43sjwRTfNdFCvo3j1RXpS6hKbLrSid7bgcbpuMFwQc4K2dbtJJKckKTjdiUrbZ6ITFDVLiVudJZ060HM8W8jJx3pFbTzw3dS7wRcxhHA7GT/eCLyN1W9WER+hqvfEsmJ7otL33w15DPdnsYorpTyNbQdJHi1ho/ZqFDV8q4eyzgwkS5UvU1nxI2VGYOr/RXPHbX3x0szA/Fj2k5BqLjUzAqNqo3fk/Fpn6fhahSdBG1HlYYFYMVNcn8mbhDUKp/GeLjGmFI1wXZEcrJH0tobDb1YxQ08rKJ9763HBYuNfcf+lkiQamK5pbrYG4l/vDQzEAnVxu/piMgPcKONI6NKI5lJez2qtJPtWInL+FhOICc7hu90LeFF1vZJW42eiYj08YkTxWH7zUiklnQzEAnVxt9fSNao0k4c/2VVjTvDl5fNw7kSptJaQuP2fZhrbvRARGSmqp4deIAI9ob32cOOEU66GYgVOLdKo1/vhasBf4js47ozBwKdyckWV+5iO621rbpcQsM48JDAbH4+QcPoAaRbFlPCc+QaCdGZnOxuK6FhHJBEqh3fIiJjcJlcL+k+KphnhJNWPQjYE1iNO0euEZ/O5GT7J8Rbo0poXK6qX0lmG439B0lhwTwjnLQzEEb3Ia5C7PWJpPVK21LWAMPZR6WsjZ6PdKLasbHvSDcXk9G9HIebyjORnOxEi5EZ6UmqC+YZIVgPwugy+zon2zjwSVXBPCMc60EYXcYMgdFdpKpgntExZiAMw+gJdKbasbGPMBeTYRiGEUpGfBHDMAwjHTEDYRiGYYRiBsIwPCLySxF5Q0SWishiP5gvWcea6wdtGkaPxYLUhgGIyPG46r6TVHW3n788J8XNMoyUYj0Iw3CUAlWquhtAVatU9QMR+W8RWSAiy0XkDhER2NMDuElEKkTkLRGZLCLTRGRVZKY+ERkpIitE5EEv808/L0cbROQMEZkvIgtF5DFfZRgRuVZE3vQ9mpTP3WykH2YgDMMxCxgmIm+LyF9E5ON++62qOllVJwJ5uF5GhAY/S97twBPA5biRwJeKSH8vMx74i6oeiqtm+93gQX1P5b+A01R1ElABXOk/fy5wmB+ZvrfTwxpGpzEDYRiAnyOkDLgM+Ah4REQuBU4WkddEZBluWtnDAh+b7l+XAW+o6kbfA1kDDPP71qvqK/7933HzYQQ5DpgAvCIii4FLgBG4chO7gLtF5DygrttO1jASxGIQhuFR1WZgLjDXG4RvAUcA5aq6XkSuxg3oihCZA6Ml8D6yvmcK1ujDRK0L8KyqXhTdHhE5BjgVOB/4Hq3znhvGPsF6EIYBiMh4ERkX2HQUrtosQJWPC5zfBdXDfQAc3CRJL0ftfxU4QUTG+nYUiMjB/nh9VfVJ4EfAkV04tmHsFdaDMAxHIW6ymiJcCfLVOHfTVtyc2x8CC7qgdyVwuYjcg5uU6rbgTlX9yLuy/uFnOAQXk9gBPCEiubhexpVdOLZh7BVWasMwkoSIjARm+gC3Yex3mIvJMAzDCMV6EIZhGEYo1oMwDMMwQjEDYRiGYYRiBsIwDMMIxQyEYRiGEYoZCMMwDCOU/w/gQtu7wmwA0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x126d54150>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "meta_freqdist.plot(30, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "## this step happens after we account for stopwords and lemmas; depending on the library...\n",
    "* we make a **Count Vector**, which is the formal term for a **bag of words**\n",
    "* we use vectors to pass text into machine learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the CountVectorizer method on 'basic_example'\n",
    "basic_example = ['The Data Scientist wants to train a machine to train machine learning models.']\n",
    "cv = CountVectorizer()\n",
    "cv.fit(basic_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what info can we get from cv?\n",
    "# hint -- look at the docs again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'models',\n",
       " 'scientist',\n",
       " 'the',\n",
       " 'to',\n",
       " 'train',\n",
       " 'wants']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2, 1, 1, 1, 2, 2, 1]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(basic_example).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 0,\n",
       " 'learning': 1,\n",
       " 'machine': 2,\n",
       " 'models': 3,\n",
       " 'scientist': 4,\n",
       " 'the': 5,\n",
       " 'to': 6,\n",
       " 'train': 7,\n",
       " 'wants': 8}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         1        2       1          1    1   2      2      1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(cv.transform(basic_example).toarray(),  columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization allows us to compare two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to help see what's happening\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fit the CountVectorizer on the 'basic_example', now we transform 'basic_example'\n",
    "example_vector_doc_1 = cv.transform(basic_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# what is the type\n",
    "\n",
    "print(type(example_vector_doc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t2\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t2\n",
      "  (0, 7)\t2\n",
      "  (0, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "# what does it look like\n",
    "\n",
    "print(example_vector_doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         1        2       1          1    1   2      2      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize it\n",
    "example_vector_df = pd.DataFrame(example_vector_doc_1.toarray(), columns=cv.get_feature_names())\n",
    "example_vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         0        0       0          1    2   0      0      0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we compare new text to the CountVectorizer fit on 'basic_example'\n",
    "new_text = ['the data scientist plotted the residual error of her model']\n",
    "new_data = cv.transform(new_text)\n",
    "new_count = pd.DataFrame(new_data.toarray(),columns=cv.get_feature_names())\n",
    "new_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this the object 'sentences' becomes the corpus\n",
    "sentences = ['The Data Scientist wants to train a machine to train machine learning models.',\n",
    "             'the data scientist plotted the residual error of her model in her analysis',\n",
    "             'Her analysis was so good, she won a Kaggle competition.',\n",
    "             'The machine gained sentience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to the docs for count vectorizer, how would we use an ngram\n",
    "# pro tip -- include stop words\n",
    "bigrams = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x55 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 65 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector = bigrams.fit_transform(sentences)\n",
    "bigram_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55 features for this corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['analysis',\n",
       " 'analysis was',\n",
       " 'competition',\n",
       " 'data',\n",
       " 'data scientist',\n",
       " 'error',\n",
       " 'error of',\n",
       " 'gained',\n",
       " 'gained sentience',\n",
       " 'good']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'There are {str(len(bigrams.get_feature_names()))} features for this corpus')\n",
    "bigrams.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>analysis was</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>data scientist</th>\n",
       "      <th>error</th>\n",
       "      <th>error of</th>\n",
       "      <th>gained</th>\n",
       "      <th>gained sentience</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>to</th>\n",
       "      <th>to train</th>\n",
       "      <th>train</th>\n",
       "      <th>train machine</th>\n",
       "      <th>wants</th>\n",
       "      <th>wants to</th>\n",
       "      <th>was</th>\n",
       "      <th>was so</th>\n",
       "      <th>won</th>\n",
       "      <th>won kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  analysis was  competition  data  data scientist  error  error of  \\\n",
       "0         0             0            0     1               1      0         0   \n",
       "1         1             0            0     1               1      1         1   \n",
       "2         1             1            1     0               0      0         0   \n",
       "3         0             0            0     0               0      0         0   \n",
       "\n",
       "   gained  gained sentience  good  ...  to  to train  train  train machine  \\\n",
       "0       0                 0     0  ...   2         2      2              2   \n",
       "1       0                 0     0  ...   0         0      0              0   \n",
       "2       0                 0     1  ...   0         0      0              0   \n",
       "3       1                 1     0  ...   0         0      0              0   \n",
       "\n",
       "   wants  wants to  was  was so  won  won kaggle  \n",
       "0      1         1    0       0    0           0  \n",
       "1      0         0    0       0    0           0  \n",
       "2      0         0    1       1    1           1  \n",
       "3      0         0    0       0    0           0  \n",
       "\n",
       "[4 rows x 55 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize it\n",
    "bigram_df = pd.DataFrame(bigram_vector.toarray(), columns=bigrams.get_feature_names())\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "## Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing} i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_sentences = ['The Data Scientist wants to train a machine to train machine learning models.',\n",
    "                    'the data scientist plotted the residual error of her model in her analysis',\n",
    "                    'Her analysis was so good, she won a Kaggle competition.',\n",
    "                    'The machine gained sentiance']\n",
    "# take out stop words\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "# fit transform the sentences\n",
    "tfidf_sentences = tfidf.fit_transform(tf_idf_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x18 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize it\n",
    "tfidf_df = pd.DataFrame(tfidf_sentences.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>error</th>\n",
       "      <th>gained</th>\n",
       "      <th>good</th>\n",
       "      <th>kaggle</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>model</th>\n",
       "      <th>models</th>\n",
       "      <th>plotted</th>\n",
       "      <th>residual</th>\n",
       "      <th>scientist</th>\n",
       "      <th>sentiance</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610575</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.366739</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  competition      data     error    gained      good    kaggle  \\\n",
       "0  0.000000     0.000000  0.240692  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.325557     0.000000  0.325557  0.412928  0.000000  0.000000  0.000000   \n",
       "2  0.366739     0.465162  0.000000  0.000000  0.000000  0.465162  0.465162   \n",
       "3  0.000000     0.000000  0.000000  0.000000  0.617614  0.000000  0.000000   \n",
       "\n",
       "   learning   machine     model    models   plotted  residual  scientist  \\\n",
       "0  0.305288  0.481384  0.000000  0.305288  0.000000  0.000000   0.240692   \n",
       "1  0.000000  0.000000  0.412928  0.000000  0.412928  0.412928   0.325557   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "3  0.000000  0.486934  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "   sentiance     train     wants       won  \n",
       "0   0.000000  0.610575  0.305288  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.465162  \n",
       "3   0.617614  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to bigrams\n",
    "bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's test out our TfidfVectorizer\n",
    "test_tdidf = tfidf.transform(['this is a test document','data at me I am a test document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x18 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a vector\n",
    "test_tdidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>error</th>\n",
       "      <th>gained</th>\n",
       "      <th>good</th>\n",
       "      <th>kaggle</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>model</th>\n",
       "      <th>models</th>\n",
       "      <th>plotted</th>\n",
       "      <th>residual</th>\n",
       "      <th>scientist</th>\n",
       "      <th>sentiance</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  competition  data  error  gained  good  kaggle  learning  \\\n",
       "0       0.0          0.0   0.0    0.0     0.0   0.0     0.0       0.0   \n",
       "1       0.0          0.0   1.0    0.0     0.0   0.0     0.0       0.0   \n",
       "\n",
       "   machine  model  models  plotted  residual  scientist  sentiance  train  \\\n",
       "0      0.0    0.0     0.0      0.0       0.0        0.0        0.0    0.0   \n",
       "1      0.0    0.0     0.0      0.0       0.0        0.0        0.0    0.0   \n",
       "\n",
       "   wants  won  \n",
       "0    0.0  0.0  \n",
       "1    0.0  0.0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf_df = pd.DataFrame(test_tdidf.toarray(), columns=tfidf.get_feature_names())\n",
    "test_tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Similarity Between Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell how similar two documents are to one another, normalizing for size, by taking the cosine similarity of the two. \n",
    "\n",
    "This number will range from [0,1], with 0 being not similar whatsoever, and 1 being the exact same. A potential application of cosine similarity is a basic recommendation engine. If you wanted to recommend articles that are most similar to other articles, you could talk the cosine similarity of all articles and return the highest one.\n",
    "\n",
    "<img src=\"./img/better_cos_similarity.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = TfidfVectorizer()\n",
    "sunday_afternoon = ['I ate a burger at burger queen and it was very good.',\n",
    "                    'I ate a hot dog at burger prince and it was bad',\n",
    "                    'I drove a racecar through your kitchen door',\n",
    "                    'I ate a hot dog at burger king and it was bad. I ate a burger at burger queen and it was very good']\n",
    "\n",
    "sample.fit(sunday_afternoon)\n",
    "text_data = sample.transform(sunday_afternoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# the 0th and 2nd index lines are very different, a number close to 0\n",
    "cosine_similarity(text_data[0],text_data[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87633608]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 0th and 3rd index lines are very similar, despite different lengths\n",
    "cosine_similarity(text_data[0],text_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from progressbar import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install progressbar2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape reddit page (takes a reddit .json url)\n",
    "# returns posts \n",
    "\n",
    "headers = {'User-Agent' : 'override this bad boy!'}\n",
    "\n",
    "def scraper_bike(url):\n",
    "    posts = []\n",
    "    after = {}\n",
    "\n",
    "    for page in progressbar(range(40)):\n",
    "        params = {'after' : after}\n",
    "        url = url\n",
    "        pagepull = requests.get(url = url, params = params, headers = headers)\n",
    "        page_dict = pagepull.json()\n",
    "        posts.extend(page_dict['data']['children'])\n",
    "        after = page_dict['data']['after']\n",
    "        time.sleep(.2)\n",
    "        \n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert posts to DataFrame - won't allow duplicate posts since unique id 'name' is set as index\n",
    "# Extract: name (as index) and subreddit, selftext, title (as columns)\n",
    "\n",
    "def posts_to_df(post_list):\n",
    "    i = 0\n",
    "    post_dict = {}\n",
    "    \n",
    "    for post in post_list:\n",
    "        ind = post_list[i]['data']\n",
    "        post_dict[ind['name']] = [ind['subreddit'], ind['title'], ind['selftext']]\n",
    "        i += 1\n",
    "\n",
    "    df_name = pd.DataFrame(post_dict)\n",
    "    df_name = df_name.T\n",
    "    df_name.columns = ['subreddit', 'title', 'selftext'] #'selftext'\n",
    "    \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes scraper function and url - outputs dataframe\n",
    "\n",
    "def scrape_to_df(scrape_func, url):\n",
    "    \n",
    "    return posts_to_df(scrape_func(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If you want to scrape repeatedly over time and add to a csv\n",
    "# scrape, import csv, concat, drop duplicate, and output to csv\n",
    "# takes in scraper function, url, csv filename to import, csv filename to output\n",
    "# Outputs - Concatenated DataFrame as csv\n",
    "\n",
    "def scrape_add(scrape_func, url, import_file, export_file):\n",
    "    scrape_df = posts_to_df(scrape_func(url))\n",
    "    imported_df = pd.read_csv(import_file, index_col = 'Unnamed: 0')\n",
    "    concat_df = pd.concat([imported_df, scrape_df])\n",
    "    concat_df = concat_df[~concat_df.index.duplicated(keep='first')]\n",
    "    concat_df.to_csv(export_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (40 of 40) |########################| Elapsed Time: 0:00:25 Time:  0:00:25\n",
      "100% (40 of 40) |########################| Elapsed Time: 0:00:25 Time:  0:00:25\n"
     ]
    }
   ],
   "source": [
    "# Run this and comment out pd.read_csv lines in data cleaning / preprocessing to use freshly scraped data\n",
    "# You can also put in any 2 subreddits in as the URL and get results for those\n",
    "\n",
    "nfltest = scrape_to_df(scraper_bike, 'https://www.reddit.com/r/nfl.json')\n",
    "nbatest = scrape_to_df(scraper_bike, 'https://www.reddit.com/r/nba.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (40 of 40) |########################| Elapsed Time: 0:00:29 Time:  0:00:29\n",
      "100% (40 of 40) |########################| Elapsed Time: 0:00:27 Time:  0:00:27\n"
     ]
    }
   ],
   "source": [
    "politics_test = scrape_to_df(scraper_bike, 'https://www.reddit.com/r/politics.json')\n",
    "conservative_test = scrape_to_df(scraper_bike, 'https://www.reddit.com/r/conservative.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(734, 3)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbatest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfltest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t3_dcc7g6</th>\n",
       "      <td>nfl</td>\n",
       "      <td>Water Cooler Wednesday</td>\n",
       "      <td>Welcome to today's open thread, where /r/nfl users can discuss anything they wish not related directly to the NFL.\\n\\nWant to talk about personal life? Cool things about your fandom? Whatever happens to be dominating today's news cycle? Do you have something to talk about that didn't warrant its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbxfyg</th>\n",
       "      <td>nfl</td>\n",
       "      <td>Official Week 4 /r/NFL Power Rankings</td>\n",
       "      <td>Good afternoon, r/nfl! We're through the first quarter of this race, with only 3 teams remaining undefeated while 6 have yet to win a game. It's early going and there's still a lot of moving around to be done, as these horses are anything but predictable. Some wild swings appear in the rankings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dcajbu</th>\n",
       "      <td>nfl</td>\n",
       "      <td>Tom Brady has been wearing the same shoulder pads since his freshman year at Michigan in 1995. They're older than 5 of his current team-mates.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dca6d5</th>\n",
       "      <td>nfl</td>\n",
       "      <td>Percy Harvin Says He Was High Every Game He Played</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc44f6</th>\n",
       "      <td>nfl</td>\n",
       "      <td>[Jaguars] The Jaguars are giving out a bandana and a mustache to any fan who purchases tickets to the team's 2 home games this month</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit  \\\n",
       "t3_dcc7g6       nfl   \n",
       "t3_dbxfyg       nfl   \n",
       "t3_dcajbu       nfl   \n",
       "t3_dca6d5       nfl   \n",
       "t3_dc44f6       nfl   \n",
       "\n",
       "                                                                                                                                                    title  \\\n",
       "t3_dcc7g6                                                                                                                          Water Cooler Wednesday   \n",
       "t3_dbxfyg                                                                                                           Official Week 4 /r/NFL Power Rankings   \n",
       "t3_dcajbu  Tom Brady has been wearing the same shoulder pads since his freshman year at Michigan in 1995. They're older than 5 of his current team-mates.   \n",
       "t3_dca6d5                                                                                              Percy Harvin Says He Was High Every Game He Played   \n",
       "t3_dc44f6            [Jaguars] The Jaguars are giving out a bandana and a mustache to any fan who purchases tickets to the team's 2 home games this month   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                              selftext  \n",
       "t3_dcc7g6  Welcome to today's open thread, where /r/nfl users can discuss anything they wish not related directly to the NFL.\\n\\nWant to talk about personal life? Cool things about your fandom? Whatever happens to be dominating today's news cycle? Do you have something to talk about that didn't warrant its...  \n",
       "t3_dbxfyg  Good afternoon, r/nfl! We're through the first quarter of this race, with only 3 teams remaining undefeated while 6 have yet to win a game. It's early going and there's still a lot of moving around to be done, as these horses are anything but predictable. Some wild swings appear in the rankings ...  \n",
       "t3_dcajbu                                                                                                                                                                                                                                                                                                               \n",
       "t3_dca6d5                                                                                                                                                                                                                                                                                                               \n",
       "t3_dc44f6                                                                                                                                                                                                                                                                                                               "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfltest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### These scrape_add functions add to already built csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_add(scraper_bike, 'https://www.reddit.com/r/CollegeBasketball/new.json', 'NCAA_Posts_Update2.csv', 'NCAA_Posts_Update3.csv')\n",
    "# scrape_add(scraper_bike, 'https://www.reddit.com/r/AskScience/new.json', 'AskSci_Posts_Update2.csv', 'AskSci_Posts_Update3.csv')\n",
    "# scrape_add(scraper_bike, 'https://www.reddit.com/r/nba/new.json', 'NBA_Posts_Update2.csv', 'NBA_Posts_Update3.csv')\n",
    "# scrape_add(scraper_bike, 'https://www.reddit.com/r/nfl/new.json', 'NFL_Posts_Update2.csv', 'NFL_Posts_Update3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning / Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "pd.set_option('max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column\n",
    "\n",
    "nfltest = nfltest.drop(columns = 'selftext')\n",
    "nbatest = nbatest.drop(columns = 'selftext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge subreddit data\n",
    "\n",
    "train = pd.concat([nfltest, nbatest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t3_dcc7g6</th>\n",
       "      <td>nfl</td>\n",
       "      <td>Water Cooler Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbxfyg</th>\n",
       "      <td>nfl</td>\n",
       "      <td>Official Week 4 /r/NFL Power Rankings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dcajbu</th>\n",
       "      <td>nfl</td>\n",
       "      <td>Tom Brady has been wearing the same shoulder pads since his freshman year at Michigan in 1995. They're older than 5 of his current team-mates.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dca6d5</th>\n",
       "      <td>nfl</td>\n",
       "      <td>Percy Harvin Says He Was High Every Game He Played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc44f6</th>\n",
       "      <td>nfl</td>\n",
       "      <td>[Jaguars] The Jaguars are giving out a bandana and a mustache to any fan who purchases tickets to the team's 2 home games this month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit  \\\n",
       "t3_dcc7g6       nfl   \n",
       "t3_dbxfyg       nfl   \n",
       "t3_dcajbu       nfl   \n",
       "t3_dca6d5       nfl   \n",
       "t3_dc44f6       nfl   \n",
       "\n",
       "                                                                                                                                                    title  \n",
       "t3_dcc7g6                                                                                                                          Water Cooler Wednesday  \n",
       "t3_dbxfyg                                                                                                           Official Week 4 /r/NFL Power Rankings  \n",
       "t3_dcajbu  Tom Brady has been wearing the same shoulder pads since his freshman year at Michigan in 1995. They're older than 5 of his current team-mates.  \n",
       "t3_dca6d5                                                                                              Percy Harvin Says He Was High Every Game He Played  \n",
       "t3_dc44f6            [Jaguars] The Jaguars are giving out a bandana and a mustache to any fan who purchases tickets to the team's 2 home games this month  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize (grab only word characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title'] = train['title'].map(lambda x: word_tokenizer.tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejoin list of tokenized words into single string for each row\n",
    "\n",
    "train['title'] = train['title'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t3_dcc7g6                                                                                                                          water cooler wednesday\n",
       "t3_dbxfyg                                                                                                            official week 4 r nfl power rankings\n",
       "t3_dcajbu    tom brady has been wearing the same shoulder pads since his freshman year at michigan in 1995 they re older than 5 of his current team mates\n",
       "t3_dca6d5                                                                                              percy harvin says he was high every game he played\n",
       "t3_dc44f6              jaguars the jaguars are giving out a bandana and a mustache to any fan who purchases tickets to the team s 2 home games this month\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['title'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split and converting series to list of strings then to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['title']]\n",
    "y = train['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nfl    0.559952\n",
       "nba    0.440048\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline is\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our training data list - this is a list of strings, with each string being a post title\n",
    "\n",
    "clean_train_data = []\n",
    "\n",
    "for traindata in X_train['title']:\n",
    "    clean_train_data.append(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1251"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test data list\n",
    "\n",
    "clean_test_data = []\n",
    "\n",
    "for testdata in X_test['title']:\n",
    "    clean_test_data.append(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our CountVectorizer. This counts the number of appearances of all the words in our training data and\n",
    "# eliminates common english stop words. 5000 max features works well for our purposes (tested various numbers). Our\n",
    "# data is already preprocessed and tokenized manually earlier. ngram_range is 1,3, although all or nearly all our\n",
    "# features are single words\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=\"word\",\n",
    "                             tokenizer=None,\n",
    "                             preprocessor=None,\n",
    "                             stop_words='english',\n",
    "                             max_features=5000,\n",
    "                             ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our training data and test data lists to our count_vectorizer\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_data)\n",
    "\n",
    "test_data_features = vectorizer.transform(clean_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to array\n",
    "\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1251, 5000), (417, 5000))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shapes\n",
    "\n",
    "train_data_features.shape, test_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I wanted check that the features corpus was as expected - removed print statement for readability\n",
    "\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '000 career',\n",
       " '04',\n",
       " '10',\n",
       " '10 2014',\n",
       " '10 catches',\n",
       " '10 catches 223',\n",
       " '10 points',\n",
       " '10 reb',\n",
       " '10 yards',\n",
       " '100',\n",
       " '100 greatest',\n",
       " '100 greatest games',\n",
       " '1000',\n",
       " '106',\n",
       " '11',\n",
       " '11 games',\n",
       " '12',\n",
       " '12 games',\n",
       " '13',\n",
       " '13 games',\n",
       " '132',\n",
       " '14',\n",
       " '140',\n",
       " '15',\n",
       " '15 000',\n",
       " '15 000 career',\n",
       " '150',\n",
       " '150 yard',\n",
       " '150 yard receiver',\n",
       " '150 yard rusher',\n",
       " '151',\n",
       " '16',\n",
       " '16 17',\n",
       " '16 games',\n",
       " '16 tds',\n",
       " '16m',\n",
       " '17',\n",
       " '17 straight',\n",
       " '17 straight games',\n",
       " '17 year',\n",
       " '179',\n",
       " '18',\n",
       " '18 65',\n",
       " '18 65 mph',\n",
       " '18 mph',\n",
       " '18 mph vs',\n",
       " '18 sacks',\n",
       " '18 snapped',\n",
       " '18 snapped streaks',\n",
       " '19',\n",
       " '19 matt',\n",
       " '19 matt ryan',\n",
       " '19 season',\n",
       " '1950',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970 merger',\n",
       " '1986',\n",
       " '1994',\n",
       " '1994 1999',\n",
       " '1997',\n",
       " '1999',\n",
       " '1st',\n",
       " '1st amp',\n",
       " '1st amp 2nd',\n",
       " '1st place',\n",
       " '20',\n",
       " '200',\n",
       " '200 snaps',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2008',\n",
       " '2010',\n",
       " '2010s',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2018 2019',\n",
       " '2019',\n",
       " '2019 20',\n",
       " '2019 2020',\n",
       " '2019 2020 season',\n",
       " '2019 nba',\n",
       " '2019 nba media',\n",
       " '2019 nfl',\n",
       " '2019 season',\n",
       " '2020',\n",
       " '2020 season',\n",
       " '21',\n",
       " '22',\n",
       " '223',\n",
       " '223 yards',\n",
       " '225',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '29 carries',\n",
       " '2nd',\n",
       " '2nd round',\n",
       " '2nd round pick',\n",
       " '30',\n",
       " '30 nba',\n",
       " '30 nba franchises',\n",
       " '30 years',\n",
       " '300',\n",
       " '300 yard',\n",
       " '300 yard passer',\n",
       " '31',\n",
       " '31st',\n",
       " '32',\n",
       " '32 games',\n",
       " '325',\n",
       " '325 second',\n",
       " '33',\n",
       " '33 yards',\n",
       " '33 yards drive',\n",
       " '34',\n",
       " '34 million',\n",
       " '342',\n",
       " '35',\n",
       " '35 starter',\n",
       " '35 years',\n",
       " '36',\n",
       " '37',\n",
       " '39',\n",
       " '3pt',\n",
       " '3rd',\n",
       " '3s',\n",
       " '40',\n",
       " '40 25',\n",
       " '40 years',\n",
       " '42',\n",
       " '43',\n",
       " '45',\n",
       " '46',\n",
       " '48',\n",
       " '49',\n",
       " '49ers',\n",
       " '4th',\n",
       " '50',\n",
       " '50 yards',\n",
       " '500',\n",
       " '500 better',\n",
       " '52',\n",
       " '53',\n",
       " '549',\n",
       " '55',\n",
       " '55 points',\n",
       " '56',\n",
       " '57th',\n",
       " '5th',\n",
       " '60',\n",
       " '63',\n",
       " '63 yards',\n",
       " '65',\n",
       " '65 mph',\n",
       " '66',\n",
       " '68',\n",
       " '69',\n",
       " '69 yards',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '7th',\n",
       " '80',\n",
       " '81',\n",
       " '81 nfl',\n",
       " '81 nfl 100',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '84 points',\n",
       " '86',\n",
       " '88',\n",
       " '89',\n",
       " '8th',\n",
       " '8th time',\n",
       " '90',\n",
       " '90 81',\n",
       " '90 81 nfl',\n",
       " '99',\n",
       " '9th',\n",
       " 'aaron',\n",
       " 'aaron fox',\n",
       " 'aaron gordon',\n",
       " 'aaron rodgers',\n",
       " 'aaron schatz']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logistic regression model\n",
    "\n",
    "lr = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1251, 5000), (1251,))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape check\n",
    "\n",
    "train_data_features.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996802557953637"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304556354916067"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a dataframe that matches features to coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = lr.coef_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = coef_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'features': vectorizer.get_feature_names(),\n",
    "                        'coefs': coef_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>nba</td>\n",
       "      <td>-2.605586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>lebron</td>\n",
       "      <td>-1.488739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>kawhi</td>\n",
       "      <td>-1.209259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>basketball</td>\n",
       "      <td>-1.180088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>harden</td>\n",
       "      <td>-1.089459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>lakers</td>\n",
       "      <td>-0.985407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>rockets</td>\n",
       "      <td>-0.977707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>warriors</td>\n",
       "      <td>-0.898148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>kd</td>\n",
       "      <td>-0.866865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>finals</td>\n",
       "      <td>-0.825422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>think</td>\n",
       "      <td>-0.803739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>paul</td>\n",
       "      <td>-0.788623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>getting</td>\n",
       "      <td>-0.777873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>kg</td>\n",
       "      <td>-0.703041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>curry</td>\n",
       "      <td>-0.698510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>shaq</td>\n",
       "      <td>-0.689908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>championship</td>\n",
       "      <td>-0.664028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>teams getting</td>\n",
       "      <td>-0.662226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>westbrook</td>\n",
       "      <td>-0.640692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>klay</td>\n",
       "      <td>-0.638784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>mvp</td>\n",
       "      <td>-0.634379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>lonzo</td>\n",
       "      <td>-0.626730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>irving</td>\n",
       "      <td>-0.619551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>height</td>\n",
       "      <td>-0.617218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>durant</td>\n",
       "      <td>-0.608381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>shooting</td>\n",
       "      <td>-0.606009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>gordon</td>\n",
       "      <td>-0.601260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>announced</td>\n",
       "      <td>-0.596852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>players</td>\n",
       "      <td>-0.583811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>best</td>\n",
       "      <td>-0.581474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>giants</td>\n",
       "      <td>0.750112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>team history</td>\n",
       "      <td>0.756021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>ravens</td>\n",
       "      <td>0.757364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>minshew</td>\n",
       "      <td>0.764041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>jaguars</td>\n",
       "      <td>0.765003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>chris</td>\n",
       "      <td>0.786487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>chiefs</td>\n",
       "      <td>0.795050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>rams</td>\n",
       "      <td>0.806426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>afc</td>\n",
       "      <td>0.815929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>fan</td>\n",
       "      <td>0.816147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>second</td>\n",
       "      <td>0.827170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>bills</td>\n",
       "      <td>0.828340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>patriots</td>\n",
       "      <td>0.855469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>games</td>\n",
       "      <td>0.855840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>browns</td>\n",
       "      <td>0.911416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>burfict</td>\n",
       "      <td>0.916751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>gruden</td>\n",
       "      <td>0.922385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>broncos</td>\n",
       "      <td>0.935807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>nfc</td>\n",
       "      <td>0.957929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>bengals</td>\n",
       "      <td>0.964358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>cowboys</td>\n",
       "      <td>1.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>weeks</td>\n",
       "      <td>1.059317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>vikings</td>\n",
       "      <td>1.082624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>dolphins</td>\n",
       "      <td>1.090936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>redskins</td>\n",
       "      <td>1.156615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>qb</td>\n",
       "      <td>1.274063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>yards</td>\n",
       "      <td>1.296762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>week</td>\n",
       "      <td>1.793695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>highlight</td>\n",
       "      <td>1.915303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>nfl</td>\n",
       "      <td>2.482734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           features     coefs\n",
       "1796            nba -2.605586\n",
       "1554         lebron -1.488739\n",
       "1457          kawhi -1.209259\n",
       "381      basketball -1.180088\n",
       "1191         harden -1.089459\n",
       "1519         lakers -0.985407\n",
       "3823        rockets -0.977707\n",
       "4456       warriors -0.898148\n",
       "1460             kd -0.866865\n",
       "978          finals -0.825422\n",
       "4253          think -0.803739\n",
       "2180           paul -0.788623\n",
       "1101        getting -0.777873\n",
       "1470             kg -0.703041\n",
       "688           curry -0.698510\n",
       "3970           shaq -0.689908\n",
       "545    championship -0.664028\n",
       "4218  teams getting -0.662226\n",
       "4682      westbrook -0.640692\n",
       "1486           klay -0.638784\n",
       "1794            mvp -0.634379\n",
       "1608          lonzo -0.626730\n",
       "1351         irving -0.619551\n",
       "1212         height -0.617218\n",
       "858          durant -0.608381\n",
       "3982       shooting -0.606009\n",
       "1141         gordon -0.601260\n",
       "294       announced -0.596852\n",
       "2855        players -0.583811\n",
       "400            best -0.581474\n",
       "...             ...       ...\n",
       "1104         giants  0.750112\n",
       "4203   team history  0.756021\n",
       "3667         ravens  0.757364\n",
       "1749        minshew  0.764041\n",
       "1368        jaguars  0.765003\n",
       "571           chris  0.786487\n",
       "567          chiefs  0.795050\n",
       "3450           rams  0.806426\n",
       "232             afc  0.815929\n",
       "950             fan  0.816147\n",
       "3947         second  0.827170\n",
       "415           bills  0.828340\n",
       "2120       patriots  0.855469\n",
       "1067          games  0.855840\n",
       "471          browns  0.911416\n",
       "491         burfict  0.916751\n",
       "1166         gruden  0.922385\n",
       "463         broncos  0.935807\n",
       "1837            nfc  0.957929\n",
       "396         bengals  0.964358\n",
       "675         cowboys  1.000032\n",
       "4634          weeks  1.059317\n",
       "4424        vikings  1.082624\n",
       "822        dolphins  1.090936\n",
       "3769       redskins  1.156615\n",
       "3220             qb  1.274063\n",
       "4962          yards  1.296762\n",
       "4571           week  1.793695\n",
       "1238      highlight  1.915303\n",
       "1841            nfl  2.482734\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values(by = ['coefs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's throw out these unfair words and rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "extra_stopwords = ['nba', 'basketball', 'football', 'nfl']\n",
    "\n",
    "stopwords.update(extra_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1251, 5000), (417, 5000))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = stopwords,\n",
    "                             max_features = 5000,\n",
    "                             ngram_range = (1, 3))\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_data)\n",
    "\n",
    "test_data_features = vectorizer.transform(clean_test_data)\n",
    "\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "train_data_features.shape, test_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9896083133493205"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8896882494004796"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>lebron</td>\n",
       "      <td>-1.431763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>kawhi</td>\n",
       "      <td>-1.196018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>harden</td>\n",
       "      <td>-1.021395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>lakers</td>\n",
       "      <td>-0.987757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>rockets</td>\n",
       "      <td>-0.986822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>india</td>\n",
       "      <td>-0.947695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>finals</td>\n",
       "      <td>-0.943875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>warriors</td>\n",
       "      <td>-0.868276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>think</td>\n",
       "      <td>-0.834553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2010s</td>\n",
       "      <td>-0.760639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>paul</td>\n",
       "      <td>-0.751345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>fact</td>\n",
       "      <td>-0.741872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>kd</td>\n",
       "      <td>-0.740472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>would</td>\n",
       "      <td>-0.733920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>height</td>\n",
       "      <td>-0.731863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>announced</td>\n",
       "      <td>-0.730571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>getting</td>\n",
       "      <td>-0.715888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>kg</td>\n",
       "      <td>-0.683502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>irving</td>\n",
       "      <td>-0.681566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>30</td>\n",
       "      <td>-0.670445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>curry</td>\n",
       "      <td>-0.667345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>shaq</td>\n",
       "      <td>-0.633755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>clippers</td>\n",
       "      <td>-0.633010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>league</td>\n",
       "      <td>-0.630491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>westbrook</td>\n",
       "      <td>-0.625447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>gordon</td>\n",
       "      <td>-0.623079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>teams getting</td>\n",
       "      <td>-0.621446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>knicks</td>\n",
       "      <td>-0.616153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>shooting</td>\n",
       "      <td>-0.604169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>players</td>\n",
       "      <td>-0.603072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>giants</td>\n",
       "      <td>0.778562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>teams</td>\n",
       "      <td>0.780221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>burfict</td>\n",
       "      <td>0.790640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3375</th>\n",
       "      <td>ravens</td>\n",
       "      <td>0.792991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>thread</td>\n",
       "      <td>0.801247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>afc</td>\n",
       "      <td>0.810112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>see</td>\n",
       "      <td>0.815685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>second</td>\n",
       "      <td>0.817766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>since</td>\n",
       "      <td>0.819325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>per</td>\n",
       "      <td>0.825795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>minshew</td>\n",
       "      <td>0.838942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>fan</td>\n",
       "      <td>0.865812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>bills</td>\n",
       "      <td>0.876552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>rams</td>\n",
       "      <td>0.885731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>team history</td>\n",
       "      <td>0.886781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>gruden</td>\n",
       "      <td>0.909738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>nfc</td>\n",
       "      <td>0.932547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>browns</td>\n",
       "      <td>0.936077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>broncos</td>\n",
       "      <td>0.961257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>vikings</td>\n",
       "      <td>0.976425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>bengals</td>\n",
       "      <td>1.012373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>sunday</td>\n",
       "      <td>1.018490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>dolphins</td>\n",
       "      <td>1.039641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>cowboys</td>\n",
       "      <td>1.075719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>weeks</td>\n",
       "      <td>1.163743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>redskins</td>\n",
       "      <td>1.255341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>qb</td>\n",
       "      <td>1.458250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>yards</td>\n",
       "      <td>1.467231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>highlight</td>\n",
       "      <td>1.863879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>week</td>\n",
       "      <td>2.008370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           features     coefs\n",
       "1646         lebron -1.431763\n",
       "1530          kawhi -1.196018\n",
       "1271         harden -1.021395\n",
       "1594         lakers -0.987757\n",
       "4174        rockets -0.986822\n",
       "1403          india -0.947695\n",
       "1016         finals -0.943875\n",
       "4842       warriors -0.868276\n",
       "4623          think -0.834553\n",
       "78            2010s -0.760639\n",
       "2080           paul -0.751345\n",
       "981            fact -0.741872\n",
       "1534             kd -0.740472\n",
       "4938          would -0.733920\n",
       "1289         height -0.731863\n",
       "297       announced -0.730571\n",
       "1178        getting -0.715888\n",
       "1545             kg -0.683502\n",
       "1429         irving -0.681566\n",
       "112              30 -0.670445\n",
       "712           curry -0.667345\n",
       "4330           shaq -0.633755\n",
       "616        clippers -0.633010\n",
       "1642         league -0.630491\n",
       "4888      westbrook -0.625447\n",
       "1221         gordon -0.623079\n",
       "4587  teams getting -0.621446\n",
       "1567         knicks -0.616153\n",
       "4342       shooting -0.604169\n",
       "2168        players -0.603072\n",
       "...             ...       ...\n",
       "1181         giants  0.778562\n",
       "4581          teams  0.780221\n",
       "512         burfict  0.790640\n",
       "3375         ravens  0.792991\n",
       "4636         thread  0.801247\n",
       "231             afc  0.810112\n",
       "4309            see  0.815685\n",
       "4300         second  0.817766\n",
       "4373          since  0.819325\n",
       "2098            per  0.825795\n",
       "1850        minshew  0.838942\n",
       "987             fan  0.865812\n",
       "435           bills  0.876552\n",
       "3162           rams  0.885731\n",
       "4571   team history  0.886781\n",
       "1246         gruden  0.909738\n",
       "1935            nfc  0.932547\n",
       "493          browns  0.936077\n",
       "485         broncos  0.961257\n",
       "4810        vikings  0.976425\n",
       "410         bengals  1.012373\n",
       "4514         sunday  1.018490\n",
       "841        dolphins  1.039641\n",
       "698         cowboys  1.075719\n",
       "4874          weeks  1.163743\n",
       "3681       redskins  1.255341\n",
       "2938             qb  1.458250\n",
       "4959          yards  1.467231\n",
       "1315      highlight  1.863879\n",
       "4858           week  2.008370\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_list = lr.coef_.tolist()\n",
    "coef_list = coef_list[0]\n",
    "\n",
    "coef_df = pd.DataFrame({'features' : vectorizer.get_feature_names(),\n",
    "                       'coefs' : coef_list})\n",
    "\n",
    "coef_df.sort_values(by = ['coefs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7937649880095923"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8465227817745803"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Matrix on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(cm,\n",
    "                    columns=['predict_neg', 'predict_pos'],\n",
    "                    index = ['actual_neg', 'actual_pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_neg</th>\n",
       "      <th>predict_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_neg</th>\n",
       "      <td>168</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_pos</th>\n",
       "      <td>30</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predict_neg  predict_pos\n",
       "actual_neg          168           16\n",
       "actual_pos           30          203"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking where our model failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({'y_actual' : y_test,\n",
    "             'y_predicted' : y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_df = comparison_df[comparison_df['y_actual'] != comparison_df['y_predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yl/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "mismatch2_df = pd.concat([mismatch_df, X_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All incorrect predictions with titles\n",
    "\n",
    "mismatches = mismatch2_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_predicted</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t3_da2dfq</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>in his first 13 seasons john stockton missed 4 nba games total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_da2ict</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>kyrie explains in depth what went wrong in boston says he failed them as a leader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_da4c56</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>robert horry game winner vs portland game 3 playoffs 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_daagf7</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>westbrook i don t have to have the ball to impact the game i don t have to score i don t have to do anything i can defend i can rebound i can pass i can lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dakizu</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>first take stephen a repeatedly changes subject to discredit jeremy lin melo comes to his defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dakreq</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>miami toronto trade idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dakzg1</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>who hit the most game winners at the buzzer regular season and playoffs combined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dan006</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>silver asks silver adam silver and nate silver in conversation 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_davzae</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>kempski nfl should discipline andrew sendejo for reckless friendly fire shot on avonte maddox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dayv8t</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>highlight pelicans draft and stash prospect didi louzada scores 24 points on 10 for 18 shooting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_db6x1t</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>who is the gardner minshew of the nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_db7vxc</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>can televised nba games ever be skipped over for another more interesting game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_db7yok</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>markelle fultz has been paid 465 640 per game played in the nba or 28 540 per minute played he is guaranteed a salary of 22 033 897 over the next two years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dba9tr</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>after starting with 3 4 on the road and going 4 0 kansas city now gets 4 5 at home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbatog</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>this season s attendance stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbbtya</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>who is a player coach who just never seemed to get the credit that they deserved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbcx8r</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>chicagobears club dub is lit after the win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbcyb1</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>hribar the falcons have now trailed by double digit points for 63 8 of their offensive snaps which is the highest rate in the league even higher than miami 62 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbdk7c</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>mike scott on beating up on an eagles fan he was talking crazy he took it to the next level so i had to see if he matched that energy gotta be the bigger person i definitely say that but as for sympathy for him i definitely don t feel any for those individuals but yeah what a day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbebuw</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>minnesota s netrtg with kg off the court his last two years before the trade to boston 2006 10 2 points per 100 2007 15 3 points per 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbfsmp</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>charger s punter ty long leads all punters with 30 points 9 9 pats 7 9 fgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbgi4u</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>who would you say has the best coaching tree of all time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbgimo</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>condotta seahawks have just announced former owner paul allen will be inducted into ring of honor thursday night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbip93</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>bordow reading into kingsbury s comments sounds like kirk is going to be out awhile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbk3e1</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>by the way i see nothing wrong with having a new york accent and being a laker fan kobe bryant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbo1oj</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>1 4 of the way through season what record do you think your team will finish with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbtm5i</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>legendary linebackers roundtable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbvglk</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>talko tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbwr08</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>salute to service 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbymtx</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>pat mcafee nfl refs have to be better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbzbu4</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>steelers depot mason rudolph juju has been an unbelievable leader for us even in the moments where he doesn t score he s positive as ever encouraging teammates he s a competitor i have to start getting him more touches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dbzqqx</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>mosqueda i need an oral history on what happened to tim williams and jachai polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc0o2v</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>sup r nfl i m patrick claybon one host of nfl now on nflnetwork and i d like to pick your collective hivemind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc0q97</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>tafur the raiders have waived eddie vanderdoes on an injury settlement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc0y0g</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>mike evans did lebron s celebration after a touchdown against the la rams and lebron tweeted about it turns out evans did it in front of kawhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc1fqp</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>george kittle on the rock calling him the people s tight end he s such an influential person the fact that someone that i ve watched and i ve idolized since i was a little kid and being able to get a response from him and gave some respect it s incredible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc2jpm</th>\n",
       "      <td>nba</td>\n",
       "      <td>nfl</td>\n",
       "      <td>not nba but ernie johnson is calling a game right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc2pt9</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>20 years ago a company called brandsmart ended up with 400 dollars worth of things bought in the store going to customers for free because of a chiefs shutout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc2vki</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>a criticism of swallowing the whistle on the fumble return and what we can learn from soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc3apg</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>kreutz baltimore lt ronnie stanley has become one of the best in the game but his nastiness is what sets him apart watch him throw the lb out of the club at the end of this play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc3tu5</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>does zimmer get the boot if vikings miss playoffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc43yr</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>jameis winston is a new man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc4hwa</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>genuine question why is bruce arians considered such an amazing coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dc9ua6</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>football s concussion crisis is awash with pseudoscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dca6d5</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>percy harvin says he was high every game he played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_dcaq1a</th>\n",
       "      <td>nfl</td>\n",
       "      <td>nba</td>\n",
       "      <td>peyton and eli manning once argued over cooper kupp at passing camp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_actual y_predicted  \\\n",
       "t3_da2dfq      nba         nfl   \n",
       "t3_da2ict      nba         nfl   \n",
       "t3_da4c56      nba         nfl   \n",
       "t3_daagf7      nba         nfl   \n",
       "t3_dakizu      nba         nfl   \n",
       "t3_dakreq      nba         nfl   \n",
       "t3_dakzg1      nba         nfl   \n",
       "t3_dan006      nba         nfl   \n",
       "t3_davzae      nfl         nba   \n",
       "t3_dayv8t      nba         nfl   \n",
       "t3_db6x1t      nba         nfl   \n",
       "t3_db7vxc      nba         nfl   \n",
       "t3_db7yok      nba         nfl   \n",
       "t3_dba9tr      nfl         nba   \n",
       "t3_dbatog      nfl         nba   \n",
       "t3_dbbtya      nfl         nba   \n",
       "t3_dbcx8r      nfl         nba   \n",
       "t3_dbcyb1      nfl         nba   \n",
       "t3_dbdk7c      nba         nfl   \n",
       "t3_dbebuw      nba         nfl   \n",
       "t3_dbfsmp      nfl         nba   \n",
       "t3_dbgi4u      nfl         nba   \n",
       "t3_dbgimo      nfl         nba   \n",
       "t3_dbip93      nfl         nba   \n",
       "t3_dbk3e1      nba         nfl   \n",
       "t3_dbo1oj      nfl         nba   \n",
       "t3_dbtm5i      nfl         nba   \n",
       "t3_dbvglk      nfl         nba   \n",
       "t3_dbwr08      nfl         nba   \n",
       "t3_dbymtx      nfl         nba   \n",
       "t3_dbzbu4      nfl         nba   \n",
       "t3_dbzqqx      nfl         nba   \n",
       "t3_dc0o2v      nfl         nba   \n",
       "t3_dc0q97      nfl         nba   \n",
       "t3_dc0y0g      nfl         nba   \n",
       "t3_dc1fqp      nfl         nba   \n",
       "t3_dc2jpm      nba         nfl   \n",
       "t3_dc2pt9      nfl         nba   \n",
       "t3_dc2vki      nfl         nba   \n",
       "t3_dc3apg      nfl         nba   \n",
       "t3_dc3tu5      nfl         nba   \n",
       "t3_dc43yr      nfl         nba   \n",
       "t3_dc4hwa      nfl         nba   \n",
       "t3_dc9ua6      nfl         nba   \n",
       "t3_dca6d5      nfl         nba   \n",
       "t3_dcaq1a      nfl         nba   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                              title  \n",
       "t3_da2dfq                                                                                                                                                                                                                            in his first 13 seasons john stockton missed 4 nba games total  \n",
       "t3_da2ict                                                                                                                                                                                                         kyrie explains in depth what went wrong in boston says he failed them as a leader  \n",
       "t3_da4c56                                                                                                                                                                                                                                 robert horry game winner vs portland game 3 playoffs 2002  \n",
       "t3_daagf7                                                                                                                             westbrook i don t have to have the ball to impact the game i don t have to score i don t have to do anything i can defend i can rebound i can pass i can lead  \n",
       "t3_dakizu                                                                                                                                                                                         first take stephen a repeatedly changes subject to discredit jeremy lin melo comes to his defense  \n",
       "t3_dakreq                                                                                                                                                                                                                                                                  miami toronto trade idea  \n",
       "t3_dakzg1                                                                                                                                                                                                          who hit the most game winners at the buzzer regular season and playoffs combined  \n",
       "t3_dan006                                                                                                                                                                                                                       silver asks silver adam silver and nate silver in conversation 2017  \n",
       "t3_davzae                                                                                                                                                                                             kempski nfl should discipline andrew sendejo for reckless friendly fire shot on avonte maddox  \n",
       "t3_dayv8t                                                                                                                                                                                           highlight pelicans draft and stash prospect didi louzada scores 24 points on 10 for 18 shooting  \n",
       "t3_db6x1t                                                                                                                                                                                                                                                     who is the gardner minshew of the nba  \n",
       "t3_db7vxc                                                                                                                                                                                                            can televised nba games ever be skipped over for another more interesting game  \n",
       "t3_db7yok                                                                                                                               markelle fultz has been paid 465 640 per game played in the nba or 28 540 per minute played he is guaranteed a salary of 22 033 897 over the next two years  \n",
       "t3_dba9tr                                                                                                                                                                                                        after starting with 3 4 on the road and going 4 0 kansas city now gets 4 5 at home  \n",
       "t3_dbatog                                                                                                                                                                                                                                                            this season s attendance stats  \n",
       "t3_dbbtya                                                                                                                                                                                                          who is a player coach who just never seemed to get the credit that they deserved  \n",
       "t3_dbcx8r                                                                                                                                                                                                                                                chicagobears club dub is lit after the win  \n",
       "t3_dbcyb1                                                                                                                          hribar the falcons have now trailed by double digit points for 63 8 of their offensive snaps which is the highest rate in the league even higher than miami 62 8  \n",
       "t3_dbdk7c  mike scott on beating up on an eagles fan he was talking crazy he took it to the next level so i had to see if he matched that energy gotta be the bigger person i definitely say that but as for sympathy for him i definitely don t feel any for those individuals but yeah what a day  \n",
       "t3_dbebuw                                                                                                                                                  minnesota s netrtg with kg off the court his last two years before the trade to boston 2006 10 2 points per 100 2007 15 3 points per 100  \n",
       "t3_dbfsmp                                                                                                                                                                                                                charger s punter ty long leads all punters with 30 points 9 9 pats 7 9 fgs  \n",
       "t3_dbgi4u                                                                                                                                                                                                                                  who would you say has the best coaching tree of all time  \n",
       "t3_dbgimo                                                                                                                                                                          condotta seahawks have just announced former owner paul allen will be inducted into ring of honor thursday night  \n",
       "t3_dbip93                                                                                                                                                                                                       bordow reading into kingsbury s comments sounds like kirk is going to be out awhile  \n",
       "t3_dbk3e1                                                                                                                                                                                            by the way i see nothing wrong with having a new york accent and being a laker fan kobe bryant  \n",
       "t3_dbo1oj                                                                                                                                                                                                         1 4 of the way through season what record do you think your team will finish with  \n",
       "t3_dbtm5i                                                                                                                                                                                                                                                          legendary linebackers roundtable  \n",
       "t3_dbvglk                                                                                                                                                                                                                                                                             talko tuesday  \n",
       "t3_dbwr08                                                                                                                                                                                                                                                                    salute to service 2019  \n",
       "t3_dbymtx                                                                                                                                                                                                                                                     pat mcafee nfl refs have to be better  \n",
       "t3_dbzbu4                                                                steelers depot mason rudolph juju has been an unbelievable leader for us even in the moments where he doesn t score he s positive as ever encouraging teammates he s a competitor i have to start getting him more touches  \n",
       "t3_dbzqqx                                                                                                                                                                                                        mosqueda i need an oral history on what happened to tim williams and jachai polite  \n",
       "t3_dc0o2v                                                                                                                                                                             sup r nfl i m patrick claybon one host of nfl now on nflnetwork and i d like to pick your collective hivemind  \n",
       "t3_dc0q97                                                                                                                                                                                                                    tafur the raiders have waived eddie vanderdoes on an injury settlement  \n",
       "t3_dc0y0g                                                                                                                                            mike evans did lebron s celebration after a touchdown against the la rams and lebron tweeted about it turns out evans did it in front of kawhi  \n",
       "t3_dc1fqp                           george kittle on the rock calling him the people s tight end he s such an influential person the fact that someone that i ve watched and i ve idolized since i was a little kid and being able to get a response from him and gave some respect it s incredible  \n",
       "t3_dc2jpm                                                                                                                                                                                                                                     not nba but ernie johnson is calling a game right now  \n",
       "t3_dc2pt9                                                                                                                            20 years ago a company called brandsmart ended up with 400 dollars worth of things bought in the store going to customers for free because of a chiefs shutout  \n",
       "t3_dc2vki                                                                                                                                                                                              a criticism of swallowing the whistle on the fumble return and what we can learn from soccer  \n",
       "t3_dc3apg                                                                                                         kreutz baltimore lt ronnie stanley has become one of the best in the game but his nastiness is what sets him apart watch him throw the lb out of the club at the end of this play  \n",
       "t3_dc3tu5                                                                                                                                                                                                                                         does zimmer get the boot if vikings miss playoffs  \n",
       "t3_dc43yr                                                                                                                                                                                                                                                               jameis winston is a new man  \n",
       "t3_dc4hwa                                                                                                                                                                                                                     genuine question why is bruce arians considered such an amazing coach  \n",
       "t3_dc9ua6                                                                                                                                                                                                                                  football s concussion crisis is awash with pseudoscience  \n",
       "t3_dca6d5                                                                                                                                                                                                                                        percy harvin says he was high every game he played  \n",
       "t3_dcaq1a                                                                                                                                                                                                                       peyton and eli manning once argued over cooper kupp at passing camp  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency / Inverse Document Frequency\n",
    "\n",
    "TF(w) = (Number of times term w appears in a document) / (Total number of terms in the document)\n",
    "\n",
    "IDF(w) = log_e(Total number of documents / Number of documents with term w in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(analyzer=\"word\",\n",
    "                            tokenizer=None,\n",
    "                            preprocessor=None,\n",
    "                            stop_words=['nba', 'nfl', 'football', 'basketball'],\n",
    "                            max_features=5000,\n",
    "                            ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1251, 5000), (417, 5000))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features = tfidf_vec.fit_transform(clean_train_data)\n",
    "\n",
    "test_data_features = tfidf_vec.transform(clean_test_data)\n",
    "\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "train_data_features.shape, test_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776179056754596"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657074340527577"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try on some other subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([politics_test, conservative_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['title']]\n",
    "y = train['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# politics_test = scrape_to_df(scraper_bike, 'https://www.reddit.com/r/politics.json')\n",
    "# conservative_test = scrape_to_df(scraper_bike, 'https://www.reddit.com/r/conservative.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_test = politics_test.drop(columns = 'selftext')\n",
    "conservative_test = conservative_test.drop(columns = 'selftext')\n",
    "\n",
    "train = pd.concat([politics_test, conservative_test])\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "train['title'] = train['title'].map(lambda x: tokenizer.tokenize(x.lower()))\n",
    "train['title'] = train['title'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our training data list - this is a list of strings, with each string being a post title\n",
    "\n",
    "clean_train_data = []\n",
    "\n",
    "for traindata in X_train['title']:\n",
    "    clean_train_data.append(traindata)\n",
    "    \n",
    "    \n",
    "# create test data list\n",
    "\n",
    "clean_test_data = []\n",
    "\n",
    "for testdata in X_test['title']:\n",
    "    clean_test_data.append(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = 'english',\n",
    "                             max_features = 5000,\n",
    "                             ngram_range = (1, 3))\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_data)\n",
    "\n",
    "test_data_features = vectorizer.transform(clean_test_data)\n",
    "\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "train_data_features.shape, test_data_features.shape\n",
    "\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1386, 5000), (1386,))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yl/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9805194805194806"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_data_features, y_train)\n",
    "\n",
    "lr.score(train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7408207343412527"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_data_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_list = lr.coef_.tolist()\n",
    "\n",
    "coef_list = coef_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>biden</td>\n",
       "      <td>-1.347266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>dems</td>\n",
       "      <td>-1.291742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>democrats</td>\n",
       "      <td>-1.080588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>media</td>\n",
       "      <td>-0.977672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>illegal</td>\n",
       "      <td>-0.960153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>deduction</td>\n",
       "      <td>-0.953604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>individual</td>\n",
       "      <td>-0.896006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>admits</td>\n",
       "      <td>-0.893303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>aoc</td>\n",
       "      <td>-0.866329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>cia</td>\n",
       "      <td>-0.840527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>democrats subpoena</td>\n",
       "      <td>-0.834918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>john</td>\n",
       "      <td>-0.833990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>liberals</td>\n",
       "      <td>-0.796729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>tom</td>\n",
       "      <td>-0.793777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>durham</td>\n",
       "      <td>-0.787691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>schiff</td>\n",
       "      <td>-0.774903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>going</td>\n",
       "      <td>-0.766578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>hoax</td>\n",
       "      <td>-0.762027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>complaint</td>\n",
       "      <td>-0.750423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>democratic party</td>\n",
       "      <td>-0.749584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>wasn</td>\n",
       "      <td>-0.746083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>judge blocks</td>\n",
       "      <td>-0.738650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>hillary</td>\n",
       "      <td>-0.717993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>donors</td>\n",
       "      <td>-0.707548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>racist</td>\n",
       "      <td>-0.702089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>demands</td>\n",
       "      <td>-0.696772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>california</td>\n",
       "      <td>-0.686342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>greta</td>\n",
       "      <td>-0.683647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>watch</td>\n",
       "      <td>-0.681210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>man</td>\n",
       "      <td>-0.673939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>modi</td>\n",
       "      <td>0.714686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>0.719718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>race ukraine</td>\n",
       "      <td>0.737061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.738915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>rudy</td>\n",
       "      <td>0.742911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>targets</td>\n",
       "      <td>0.747054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>explained</td>\n",
       "      <td>0.753121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>collins</td>\n",
       "      <td>0.767995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>marijuana</td>\n",
       "      <td>0.770659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>fbi</td>\n",
       "      <td>0.774606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>zuckerberg</td>\n",
       "      <td>0.786210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>barr</td>\n",
       "      <td>0.827140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>white</td>\n",
       "      <td>0.844041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>grassley</td>\n",
       "      <td>0.890231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>fair</td>\n",
       "      <td>0.910812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>defense</td>\n",
       "      <td>0.915246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>key</td>\n",
       "      <td>0.931959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>democracy</td>\n",
       "      <td>0.958373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>yang</td>\n",
       "      <td>0.973892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>warren</td>\n",
       "      <td>0.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>1.021039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>foreign</td>\n",
       "      <td>1.067222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>officials</td>\n",
       "      <td>1.138850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>sanders</td>\n",
       "      <td>1.146521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>poll</td>\n",
       "      <td>1.183685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3674</th>\n",
       "      <td>republicans</td>\n",
       "      <td>1.284460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>giuliani</td>\n",
       "      <td>1.313860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>manufacturing</td>\n",
       "      <td>1.348166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>trump</td>\n",
       "      <td>1.608856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>pompeo</td>\n",
       "      <td>2.059181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                features     coefs\n",
       "265                biden -1.347266\n",
       "663                 dems -1.291742\n",
       "651            democrats -1.080588\n",
       "1522               media -0.977672\n",
       "1184             illegal -0.960153\n",
       "627            deduction -0.953604\n",
       "1230          individual -0.896006\n",
       "89                admits -0.893303\n",
       "166                  aoc -0.866329\n",
       "448                  cia -0.840527\n",
       "658   democrats subpoena -0.834918\n",
       "1309                john -0.833990\n",
       "1427            liberals -0.796729\n",
       "4083                 tom -0.793777\n",
       "762               durham -0.787691\n",
       "3789              schiff -0.774903\n",
       "1006               going -0.766578\n",
       "1121                hoax -0.762027\n",
       "511            complaint -0.750423\n",
       "650     democratic party -0.749584\n",
       "4736                wasn -0.746083\n",
       "1329        judge blocks -0.738650\n",
       "1112             hillary -0.717993\n",
       "738               donors -0.707548\n",
       "3104              racist -0.702089\n",
       "644              demands -0.696772\n",
       "354           california -0.686342\n",
       "1039               greta -0.683647\n",
       "4737               watch -0.681210\n",
       "1489                 man -0.673939\n",
       "...                  ...       ...\n",
       "1577                modi  0.714686\n",
       "603            dangerous  0.719718\n",
       "3089        race ukraine  0.737061\n",
       "19                  2020  0.738915\n",
       "3732                rudy  0.742911\n",
       "4012             targets  0.747054\n",
       "847            explained  0.753121\n",
       "480              collins  0.767995\n",
       "1496           marijuana  0.770659\n",
       "883                  fbi  0.774606\n",
       "4998          zuckerberg  0.786210\n",
       "235                 barr  0.827140\n",
       "4805               white  0.844041\n",
       "1034            grassley  0.890231\n",
       "861                 fair  0.910812\n",
       "637              defense  0.915246\n",
       "1351                 key  0.931959\n",
       "647            democracy  0.958373\n",
       "4967                yang  0.973892\n",
       "4703              warren  0.988900\n",
       "539           conspiracy  1.021039\n",
       "930              foreign  1.067222\n",
       "1794           officials  1.138850\n",
       "3760             sanders  1.146521\n",
       "2138                poll  1.183685\n",
       "3674         republicans  1.284460\n",
       "995             giuliani  1.313860\n",
       "1490       manufacturing  1.348166\n",
       "4122               trump  1.608856\n",
       "2181              pompeo  2.059181\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({'features' : vectorizer.get_feature_names(),\n",
    "                       'coefs' : coef_list})\n",
    "\n",
    "coef_df.sort_values(by = ['coefs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9963924963924964\n",
      "0.755939524838013\n"
     ]
    }
   ],
   "source": [
    "pc_forest = RandomForestClassifier(n_estimators = 100)\n",
    "pc_forest.fit(train_data_features, y_train)\n",
    "print(pc_forest.score(train_data_features, y_train))\n",
    "print(pc_forest.score(test_data_features, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(s_words).extend(['nba'....])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_words = set(stopwords.words('english') + stopwords.words('spanish'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web Scraping Tutorial using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requesting data from internet\n",
    "import requests\n",
    "url = 'https://venmo.com/api/v5/public'\n",
    "resp = requests.get(url)\n",
    "\n",
    "assert(resp.status_code == 200)\n",
    "# throw error is the statement is not true\n",
    "\n",
    "content = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paging', 'data'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content.get('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content['data'])\n",
    "# the same as above one, but .get doesn't have to specific whether it's a list or dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content.get('dataz', []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is a typo of data --> dataz, this means .get will return 0 if there is no dataz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['payment_id', 'permalink', 'via', 'action_links', 'transactions', 'story_id', 'comments', 'updated_time', 'audience', 'actor', 'created_time', 'mentions', 'message', 'type', 'likes'])\n"
     ]
    }
   ],
   "source": [
    "print(content.get('data')[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars swag\n",
      "üëÖ\n",
      "Batteries\n",
      "‚õΩÔ∏è‚ù§Ô∏è\n",
      "Thrive!\n",
      "üëô\n",
      "üè†üí∏\n",
      "üí¶üí∏\n",
      "üîåüíª\n",
      "üë∂\n",
      "Starter in Accord\n",
      "üê± üéâ\n",
      "Cabana\n",
      "Makeup\n",
      "Omg stahp lol\n",
      "üì∑üë∂\n",
      "Slop\n",
      "üíá\n",
      "üçä\n",
      "‚öΩÔ∏è\n"
     ]
    }
   ],
   "source": [
    "print(*[x['message'] for x in content.get('data')], sep='\\n')\n",
    "# * and sep together to seperate text in different lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üëÖ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.get('data')[1].get('message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(content.get('data')[1].get('message'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The components of a web page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we visit a web page, our web browser makes a GET request to a web server. The server then sends back files that tell our browser how to render the page for us. The files fall into a few main types:\n",
    "\n",
    "- HTML ‚Äî contain the main content of the page.\n",
    "- CSS ‚Äî add styling to make the page look nicer.\n",
    "- JS ‚Äî Javascript files add interactivity to web pages.\n",
    "- Images ‚Äî image formats, such as JPG and PNG allow web pages to show pictures.\n",
    "\n",
    "After our browser receives all the files, it renders the page and displays it to us. There‚Äôs a lot that happens behind the scenes to render a page nicely, but we don‚Äôt need to worry about most of it when we‚Äôre web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "\n",
    "\n",
    "HyperText Markup Language (HTML) is a language that web pages are created in. HTML isn‚Äôt a programming language, like Python ‚Äî instead, it‚Äôs a markup language that tells a browser how to layout content. \n",
    "\n",
    "Let‚Äôs take a quick tour through HTML so we know enough to scrape effectively. HTML consists of elements called tags. The most basic tag is the `<html>` tag. This tag tells the web browser that everything inside of it is HTML. We can make a simple HTML document just using this tag:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "</html>\n",
    "~~~\n",
    "&#x2B07; Example cell with html in Markdown!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right inside an html tag, we put two other tags, the head tag, and the body tag. The main content of the web page goes into the body tag. The head tag contains data about the title of the page, and other information that generally isn‚Äôt useful in web scraping:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "    </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We‚Äôll now add our first content to the page, in the form of the p tag. The p tag defines a paragraph, and any text inside the tag is shown as a separate paragraph:\n",
    "~~~\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "          <p>\n",
    "            Here's a paragraph of text!\n",
    "        </p>\n",
    "        <p>\n",
    "            Here's a second paragraph of text!\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "          <p>\n",
    "            Here's a paragraph of text!\n",
    "        </p>\n",
    "        <p>\n",
    "            Here's a second paragraph of text!\n",
    "        </p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags have commonly used names that depend on their position in relation to other tags:\n",
    "\n",
    "- **child** ‚Äî a child is a tag inside another tag. So the two p tags above are both children of the body tag.\n",
    "- **parent** ‚Äî a parent is the tag another tag is inside. Above, the html tag is the parent of the body tag.\n",
    "- **sibiling** ‚Äî a sibiling is a tag that is nested inside the same parent as another tag. For example, head and body are siblings, since they‚Äôre both inside html. Both p tags are siblings, since they‚Äôre both inside body."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add properties to HTML tags that change their behavior:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "  <head></head>\n",
    "  <body>\n",
    "    <p>\n",
    "      Here's a paragraph of text!\n",
    "      <a href=\"https://www.dataquest.io\">Learn Data Science Online</a>\n",
    "    </p>\n",
    "    <p>\n",
    "      Here's a second paragraph of text!\n",
    "      <a href=\"https://www.python.org\">Python</a>        \n",
    "    </p>\n",
    "  </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p>\n",
    "            Here's a paragraph of text!\n",
    "            <a href=\"https://www.dataquest.io\">Learn Data Science Online</a>\n",
    "        </p>\n",
    "        <p>\n",
    "            Here's a second paragraph of text!\n",
    "            <a href=\"https://www.python.org\">Python</a>        </p>\n",
    "    </body></html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we added two a tags. a tags are links, and tell the browser to render a link to another web page. The href property of the tag determines where the link goes.\n",
    "\n",
    "a and p are extremely common html tags. Here are a few others:\n",
    "\n",
    "- *div* ‚Äî indicates a division, or area, of the page.\n",
    "- *b* ‚Äî bolds any text inside.\n",
    "- *i* ‚Äî italicizes any text inside.\n",
    "- *table* ‚Äî creates a table.\n",
    "- *form* ‚Äî creates an input form.\n",
    "\n",
    "\n",
    "For a full list of tags, look [here](https://developer.mozilla.org/en-US/docs/Web/HTML/Element)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two special properties give HTML elements names, and make them easier to interact with when we‚Äôre scraping, **class** and **id** properties. \n",
    "\n",
    "- One element can have multiple classes, and a class can be shared between elements. \n",
    "- Each element can only have one id, and an id can only be used once on a page. \n",
    "- Classes and ids are optional, and not all elements will have them.\n",
    "\n",
    "We can add classes and ids to our example:\n",
    "white space matters when it comes to class\n",
    "~~~\n",
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"bold-paragraph\">\n",
    "            Here's a paragraph of text!\n",
    "            <a href=\"https://www.dataquest.io\" id=\"learn-link\">Learn Data Science Online</a>\n",
    "        </p>\n",
    "        <p class=\"bold-paragraph extra-large\">\n",
    "            Here's a second paragraph of text!\n",
    "            <a href=\"https://www.python.org\" class=\"extra-large\">Python</a>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "~~~\n",
    "assign class, can apply changes later by calling class name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <head>\n",
    "    </head>\n",
    "    <body>\n",
    "        <p class=\"bold-paragraph\">\n",
    "            Here's a paragraph of text!\n",
    "            <a href=\"https://www.dataquest.io\" id=\"learn-link\">Learn Data Science Online</a>\n",
    "        </p>\n",
    "        <p class=\"bold-paragraph extra-large\">\n",
    "            Here's a second paragraph of text!\n",
    "            <a href=\"https://www.python.org\" class=\"extra-large\">Python</a>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply this knowledge\n",
    "\n",
    "Let's go to a webpage and change some of the HTML to see what happens. \n",
    "\n",
    "- Open up a webpage in Chrome.\n",
    "- Right click and 'inspect element.\n",
    "\n",
    "- Change the text in a tag.\n",
    "- Change the class of a tag.\n",
    "- Find a tag with an ID and remove it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The requests library\n",
    "The first thing we‚Äôll need to do to scrape a web page is to download the page. We can download pages using the Python requests library (similar to interacting with APIs!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "page\n",
    "# request status of 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running our request, we get a Response object. This object has a status_code property, which indicates if the page was downloaded successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out the HTML content of the page using the content property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "    <head>\n",
      "        <title>A simple example page</title>\n",
      "    </head>\n",
      "    <body>\n",
      "        <p>Here is some simple content for this page.</p>\n",
      "    </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(page.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing a page with BeautifulSoup\n",
    "\n",
    "We can use the BeautifulSoup library to parse this document, and extract the text from the `<p>` tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "# soup object is not a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())\n",
    "# prettify to make it cleaner and more readable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all the tags are nested, we can move through the structure one level at a time. We can first select all the elements at the top level of the page using the `children` property of `soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html', <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)\n",
    "# doctype = html\n",
    "# two childrem = head and body\n",
    "# list has two element, 1st is html, 2nd is the two children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above tells us that there are two tags at the top level of the page ‚Äî the initial `<!DOCTYPE html>` tag, and the `<html>` tag. There is a newline character `(\\n)` in the list as well. Let‚Äôs see what the type of each element in the list is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype, bs4.element.Tag]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(item) for item in list(soup.children)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tag` object allows us to navigate through an HTML document, and extract other tags and text. You can learn more about the various `BeautifulSoup` objects [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kinds-of-objects).\n",
    "\n",
    "We can now select the html tag and its children by taking the second item in the list:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = list(soup.children)[1]\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the list returned by the `children` property is also a `BeautifulSoup` object, so we can also call the `children` method on `html`.\n",
    "\n",
    "Now, we can find the `children` inside the `html` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <head>\n",
       " <title>A simple example page</title>\n",
       " </head>, '\\n', <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>, '\\n']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(html.children)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there are two tags here, `head`, and `body`. We want to extract the text inside the `p` tag, so we‚Äôll dive into the body:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = list(html.children)[3]\n",
    "body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now isolate the `p` tag:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = list(body.children)[1]\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we‚Äôve isolated the tag, we can use the `get_text` method to extract all of the text inside the tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding all instances of a tag at once\n",
    "\n",
    "If we want to extract a single tag, we can instead use the find_all method, which will find all the instances of a tag on a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Here is some simple content for this page.</p>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup.find_all('p')\n",
    "# return a list of ps, in this case just 1\n",
    "# imagine soup like the entire document, the top level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `find_all` returns a list, so we‚Äôll have to loop through, or use list indexing, it to extract text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0].get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you instead only want to find the first instance of a tag, you can use the `find` method, which will return a single `BeautifulSoup` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for tags by class and id\n",
    "\n",
    "\n",
    "We introduced classes and ids earlier, but it probably wasn‚Äôt clear why they were useful. Classes and ids are used by CSS to determine which HTML elements to apply certain styles to. We can also use them when scraping to specify specific elements we want to scrape. Let's look at the following page:\n",
    "\n",
    "~~~\n",
    "<html>\n",
    "    <head>\n",
    "        <title>A simple example page</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <p class=\"inner-text first-item\" id=\"first\">\n",
    "                First paragraph.\n",
    "            </p>\n",
    "            <p class=\"inner-text\">\n",
    "                Second paragraph.\n",
    "            </p>\n",
    "        </div>\n",
    "        <p class=\"outer-text first-item\" id=\"second\">\n",
    "            <b>\n",
    "                First outer paragraph.\n",
    "            </b>\n",
    "        </p>\n",
    "        <p class=\"outer-text\">\n",
    "            <b>\n",
    "                Second outer paragraph.\n",
    "            </b>\n",
    "        </p>\n",
    "    </body>\n",
    "</html>\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `find_all` method to search for items by class or by id. In the below example, we‚Äôll search for any `p` tag that has the class `outer-text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>, <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='outer-text')\n",
    "# class that's a structure and reserved word in python\n",
    "# start with a tag and then go to class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below example, we‚Äôll look for any tag that has the class `outer-text`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>, <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"outer-text\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for elements by `id`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(id=\"first\") # return the first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CSS Selectors\n",
    "\n",
    "\n",
    "You can also search for items using CSS selectors. These selectors are how the CSS language allows developers to specify HTML tags to style. Here are some examples:\n",
    "\n",
    "- *p a* ‚Äî finds all a tags inside of a p tag.\n",
    "- *body p a* ‚Äî finds all a tags inside of a p tag inside of a body tag.\n",
    "- *html body* ‚Äî finds all body tags inside of an html tag.\n",
    "- *p.outer-text* ‚Äî finds all p tags with a class of outer-text.\n",
    "- *p#first* ‚Äî finds all p tags with an id of first.\n",
    "- *body p.outer-text* ‚Äî finds any p tags with a class of outer-text inside of a body tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BeautifulSoup` objects support searching a page via CSS selectors using the `select` method. We can use CSS selectors to find all the `p` tags in our page that are inside of a `div` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>\n",
       " <input checked=\"checked\" id=\"nws\" name=\"affiliate\" type=\"radio\" value=\"nws.noaa.gov\"/>\n",
       " <label class=\"search-scope\" for=\"nws\">NWS</label>\n",
       " <input id=\"noaa\" name=\"affiliate\" type=\"radio\" value=\"noaa.gov\"/>\n",
       " <label class=\"search-scope\" for=\"noaa\">All NOAA</label>\n",
       " </p>, <p>Your local forecast office is</p>, <p>\n",
       "             A cold front stretching from the Central U.S. to the Northeast States will contribute to the possibility of severe thunderstorms Tuesday and Wednesday in the central &amp; northern Plains, Midwest, Ohio Valley, and Great Lakes region. Large hail, damaging winds, and isolated flash flooding are the main threats.\n",
       "             <a href=\"http://www.wpc.ncep.noaa.gov/discussions/hpcdiscussions.php?disc=pmdspd\" target=\"_blank\">Read More &gt;</a>\n",
       " </p>, <p class=\"myforecast-current\">A Few Clouds</p>, <p class=\"myforecast-current-lrg\">88¬∞F</p>, <p class=\"myforecast-current-sm\">31¬∞C</p>, <p class=\"moreInfo\"><b>More Information:</b></p>, <p><a href=\"https://www.weather.gov/lwx\" id=\"localWFO\" title=\"Baltimore, MD/Washington, D.C.\"><span class=\"hideText\">Local</span> Forecast Office</a><a href=\"obslocal.php?warnzone=DCZ001&amp;local_place=Washington DC&amp;zoneid=EDT&amp;offset=14400\" id=\"moreWx\">More Local Wx</a><a href=\"//www.weather.gov/data/obhistory/KDCA.html\" id=\"3dayHist\">3 Day History</a><a href=\"//mobile.weather.gov/index.php?lat=38.8977&amp;lon=-77.0365&amp;unit=0&amp;lg=english\" id=\"mobileWxLink\">Mobile Weather</a><a href=\"MapClick.php?lat=38.8977&amp;lon=-77.0365&amp;unit=0&amp;lg=english&amp;FcstType=graphical\" id=\"wxGraph\">Hourly <span class=\"hideText\">Weather </span>Forecast</a></p>, <p class=\"period-name\">This<br/>Afternoon</p>, <p><img alt=\"This Afternoon: Scattered showers and thunderstorms, mainly after 5pm.  Partly sunny, with a high near 90. South wind around 8 mph.  Chance of precipitation is 30%.\" class=\"forecast-icon\" src=\"newimages/medium/scttsra30.png\" title=\"This Afternoon: Scattered showers and thunderstorms, mainly after 5pm.  Partly sunny, with a high near 90. South wind around 8 mph.  Chance of precipitation is 30%.\"/></p>, <p class=\"short-desc\">Scattered<br/>T-storms</p>, <p class=\"temp temp-high\">High: 90 ¬∞F</p>, <p class=\"period-name\">Tonight<br/><br/></p>, <p><img alt=\"Tonight: Scattered showers and thunderstorms before 11pm, then a slight chance of showers between 11pm and 2am.  Mostly cloudy, with a low around 74. South wind around 7 mph.  Chance of precipitation is 40%.\" class=\"forecast-icon\" src=\"DualImage.php?i=nscttsra&amp;j=hi_nshwrs&amp;ip=40&amp;jp=20\" title=\"Tonight: Scattered showers and thunderstorms before 11pm, then a slight chance of showers between 11pm and 2am.  Mostly cloudy, with a low around 74. South wind around 7 mph.  Chance of precipitation is 40%.\"/></p>, <p class=\"short-desc\">Scattered<br/>T-storms then<br/>Slight Chance<br/>Showers</p>, <p class=\"temp temp-low\">Low: 74 ¬∞F</p>, <p class=\"period-name\">Wednesday<br/><br/></p>, <p><img alt=\"Wednesday: Showers and thunderstorms likely, mainly after 3pm.  Partly sunny, with a high near 91. South wind 5 to 10 mph.  Chance of precipitation is 60%. New rainfall amounts between a quarter and half of an inch possible. \" class=\"forecast-icon\" src=\"DualImage.php?i=bkn&amp;j=tsra&amp;jp=60\" title=\"Wednesday: Showers and thunderstorms likely, mainly after 3pm.  Partly sunny, with a high near 91. South wind 5 to 10 mph.  Chance of precipitation is 60%. New rainfall amounts between a quarter and half of an inch possible. \"/></p>, <p class=\"short-desc\">Partly Sunny<br/>then T-storms<br/>Likely</p>, <p class=\"temp temp-high\">High: 91 ¬∞F</p>, <p class=\"period-name\">Wednesday<br/>Night</p>, <p><img alt=\"Wednesday Night: Showers and thunderstorms likely before 2am, then a slight chance of showers.  Mostly cloudy, with a low around 71. Southwest wind 5 to 7 mph becoming calm  after midnight.  Chance of precipitation is 60%. New rainfall amounts between a tenth and quarter of an inch, except higher amounts possible in thunderstorms. \" class=\"forecast-icon\" src=\"DualImage.php?i=ntsra&amp;j=nshra&amp;ip=60&amp;jp=40\" title=\"Wednesday Night: Showers and thunderstorms likely before 2am, then a slight chance of showers.  Mostly cloudy, with a low around 71. Southwest wind 5 to 7 mph becoming calm  after midnight.  Chance of precipitation is 60%. New rainfall amounts between a tenth and quarter of an inch, except higher amounts possible in thunderstorms. \"/></p>, <p class=\"short-desc\">T-storms<br/>Likely then<br/>Chance<br/>Showers</p>, <p class=\"temp temp-low\">Low: 71 ¬∞F</p>, <p class=\"period-name\">Thursday<br/><br/></p>, <p><img alt=\"Thursday: Mostly sunny, with a high near 91. West wind 3 to 7 mph. \" class=\"forecast-icon\" src=\"newimages/medium/sct.png\" title=\"Thursday: Mostly sunny, with a high near 91. West wind 3 to 7 mph. \"/></p>, <p class=\"short-desc\">Mostly Sunny</p>, <p class=\"temp temp-high\">High: 91 ¬∞F</p>, <p class=\"period-name\">Thursday<br/>Night</p>, <p><img alt=\"Thursday Night: A slight chance of showers after 2am.  Partly cloudy, with a low around 73. Chance of precipitation is 20%.\" class=\"forecast-icon\" src=\"DualImage.php?i=nsct&amp;j=hi_nshwrs&amp;jp=20\" title=\"Thursday Night: A slight chance of showers after 2am.  Partly cloudy, with a low around 73. Chance of precipitation is 20%.\"/></p>, <p class=\"short-desc\">Partly Cloudy<br/>then Slight<br/>Chance<br/>Showers</p>, <p class=\"temp temp-low\">Low: 73 ¬∞F</p>, <p class=\"period-name\">Friday<br/><br/></p>, <p><img alt=\"Friday: A chance of showers after noon.  Partly sunny, with a high near 89. Chance of precipitation is 30%.\" class=\"forecast-icon\" src=\"DualImage.php?i=bkn&amp;j=shra&amp;jp=30\" title=\"Friday: A chance of showers after noon.  Partly sunny, with a high near 89. Chance of precipitation is 30%.\"/></p>, <p class=\"short-desc\">Partly Sunny<br/>then Chance<br/>Showers</p>, <p class=\"temp temp-high\">High: 89 ¬∞F</p>, <p class=\"period-name\">Friday<br/>Night</p>, <p><img alt=\"Friday Night: Mostly clear, with a low around 67.\" class=\"forecast-icon\" src=\"newimages/medium/nfew.png\" title=\"Friday Night: Mostly clear, with a low around 67.\"/></p>, <p class=\"short-desc\">Mostly Clear</p>, <p class=\"temp temp-low\">Low: 67 ¬∞F</p>, <p class=\"period-name\">Saturday<br/><br/></p>, <p><img alt=\"Saturday: Sunny, with a high near 87.\" class=\"forecast-icon\" src=\"newimages/medium/few.png\" title=\"Saturday: Sunny, with a high near 87.\"/></p>, <p class=\"short-desc\">Sunny</p>, <p class=\"temp temp-high\">High: 87 ¬∞F</p>, <p class=\"myforecast-location\"><a href=\"MapClick.php?zoneid=DCZ001\">Zone Area Forecast for District of Columbia, DC</a></p>, <p><a href=\"//graphical.weather.gov/sectors/nemetro.php?element=MaxT\">High Temperature</a></p>, <p><a href=\"//graphical.weather.gov/sectors/nemetro.php?element=Wx\">Chance of Precipitation</a></p>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div p\")\n",
    "# select --> a list of objects filled with soup objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `select` method above returns a list of `BeautifulSoup` objects, just like `find` and `find_all`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn: Downloading weather data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know enough to proceed with extracting information about the local weather from the National Weather Service website. The first step is to find the page we want to scrape. We‚Äôll extract weather information about downtown DC from this [page](http://forecast.weather.gov/MapClick.php?lat=38.8977&lon=-77.0365)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then scroll up in the elements panel to find the ‚Äúoutermost‚Äù element that contains all of the text that corresponds to the extended forecasts. In this case, it‚Äôs a `div` tag with the id `seven-day-forecast`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know enough to download the page and start parsing it. Below let's implement the following:\n",
    "\n",
    "1. Download the web page containing the forecast.\n",
    "2. Create a `BeautifulSoup` class to parse the page.\n",
    "3. Find the `div` with id `seven-day-forecast`, and assign to `seven_day`\n",
    "4. Inside `seven_day`, find each individual forecast item.\n",
    "5. Extract and print the first forecast item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "page = requests.get(\"https://forecast.weather.gov/MapClick.php?lat=38.8977&lon=-77.0365#.XUm9spJKh24\")\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_day = soup.find_all(id='seven-day-forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seven_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find_all'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-c5305cbebdfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseven_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'forecast-tombstone'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         raise AttributeError(\n\u001b[0;32m-> 1620\u001b[0;31m             \u001b[0;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find_all'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "forecast = seven_day.find_all(class_='forecast-tombstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-259bd48575ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         raise AttributeError(\n\u001b[0;32m-> 1620\u001b[0;31m             \u001b[0;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'get_text'. You're probably treating a list of items like a single item. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "forecast.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information from the page\n",
    "As you can see, inside the forecast item `tonight` is all the information we want. There are `4` pieces of information we can extract:\n",
    "\n",
    "- The name of the forecast item ‚Äî in this case, **Tonight**.\n",
    "- The description of the conditions ‚Äî this is stored in the `title` property of `img`.\n",
    "- A short description of the conditions ‚Äî in this case, **Mostly Clear**.\n",
    "- The temperature low ‚Äî in this case, **49 degrees**.\n",
    "\n",
    "We‚Äôll extract the name of the forecast item, the short description, and the temperature first, since they‚Äôre all similar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract the `title` attribute from the `img` tag. To do this, we just treat the `BeautifulSoup` object like a dictionary, and pass in the attribute we want as a key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all the information from the page\n",
    "Now that we know how to extract each individual piece of information, we can combine our knowledge with css selectors and list comprehensions to extract everything at once.\n",
    "\n",
    "In the below code, we:\n",
    "\n",
    "- Select all items with the class period-name inside an item with the class tombstone-container in seven_day.\n",
    "- Use a list comprehension to call the get_text method on each BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our technique gets us each of the period names, in order. Now you can apply the same technique to get the other 3 fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_descs = [sd.get_text()for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "\n",
    "print(short_descs)\n",
    "print(temps)\n",
    "print(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining our data into a Pandas Dataframe\n",
    "\n",
    "We can now combine the data into a Pandas DataFrame and analyze it.\n",
    "\n",
    "In order to do this, we‚Äôll call the DataFrame class, and pass in each list of items that we have. We pass them in as part of a dictionary. Each dictionary key will become a column in the DataFrame, and each list will become the values in the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "weather = pd.DataFrame({\n",
    "    \"period\": periods,\n",
    "    \"short_desc\": short_descs,\n",
    "    \"temp\": temps,\n",
    "    \"desc\": descs\n",
    "})\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do some analysis on the data. For example, we can use a regular expression and the Series.str.extract method to pull out the numeric temperature values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nums = weather[\"temp\"].str.extract(\"(?P<temp_num>\\d+)\", expand=False)\n",
    "weather[\"temp_num\"] = temp_nums.astype('int')\n",
    "temp_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then find the mean of all the high and low temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"temp_num\"].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also only select the rows that happen at night:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_night = weather[\"temp\"].str.contains(\"Low\")\n",
    "weather[\"is_night\"] = is_night\n",
    "is_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[is_night]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
